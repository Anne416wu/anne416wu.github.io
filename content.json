{"pages":[{"title":"About","text":"BIT/CS/Junior 考研","link":"/about/index.html"},{"title":"Project","text":"","link":"/project/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Dudes","text":"Follow the notes upon a journey At first sight marks one's destinyOnce the voyage comes to an endReturn lies within hasty keys 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","link":"/posts/27073/"},{"title":"Anaconda的环境管理","text":"常用的Conda命令 Conda的环境管理Conda的环境管理功能允许我们同时安装若干不同版本的Python，并能自由切换。对于上述安装过程，假设我们采用的是Python 2.7对应的安装包，那么Python 2.7就是默认的环境（默认名字是root注意这个root不是超级管理员的意思）。假设我们需要安装Python 3.4，此时，我们需要做的操作如下： 12345678910111213141516171819# 创建一个名为python34的环境，指定Python版本是3.4（不用管是3.4.x，conda会为我们自动寻找3.4.x中的最新版本）conda create —name python34 python=3.4# 安装好后，使用activate激活某个环境activate python34 # for Windowssource activate python34 # for Linux &amp; Mac# 激活后，会发现terminal输入的地方多了python34的字样，实际上，此时系统做的事情就是把默认2.7环境从PATH中去除，再把3.4对应的命令加入PATH# 此时，再次输入python —version# 可以得到`Python 3.4.5 :: Anaconda 4.1.1 (64-bit)`，即系统已经切换到了3.4的环境# 如果想返回默认的python 2.7环境，运行deactivate python34 # for Windowssource deactivate python34 # for Linux conda deactivate python34 # for mac# 删除一个已有的环境conda remove —name python34 —all 用户安装的不同python环境都会被放在目录~/anaconda/envs下，可以在命令中运行conda info -e查看已安装的环境，当前被激活的环境会显示有一个星号或者括号。说明：有些用户可能经常使用python 3.4环境，因此直接把~/anaconda/envs/python34下面的bin或者Scripts加入PATH，去除anaconda对应的那个bin目录。这个办法，怎么说呢，也是可以的，但总觉得不是那么elegant……如果直接按上面说的这么改PATH，你会发现conda命令又找不到了（当然找不到啦，因为conda在~/anaconda/bin里呢），这时候怎么办呢？方法有二：1. 显式地给出conda的绝对地址 2. 在python34环境中也安装conda工具（推荐）。 Conda的包管理 Conda的包管理就比较好理解了，这部分功能与pip类似。例如，如果需要安装scipy： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 安装scipyconda install scipy# conda会从从远程搜索scipy的相关信息和依赖项目，对于python 3.4，conda会同时安装numpy和mkl（运算加速的库）# 查看已经安装的packagesconda list# 最新版的conda是从site-packages文件夹中搜索已经安装的包，不依赖于pip，因此可以显示出通过各种方式安装的包# 安装scipyconda install scipy# conda会从从远程搜索scipy的相关信息和依赖项目，对于python 3.4，conda会同时安装numpy和mkl（运算加速的库）# 查看已经安装的packagesconda list# 最新版的conda是从site-packages文件夹中搜索已经安装的包，不依赖于pip，因此可以显示出通过各种方式安装的包### conda的一些常用操作如下：# 查看当前环境下已安装的包conda list# 查看某个指定环境的已安装包conda list -n python34# 查找package信息conda search numpy# 安装packageconda install -n python34 numpy# 如果不用-n指定环境名称，则被安装在当前活跃环境# 也可以通过-c指定通过某个channel安装# 更新packageconda update -n python34 numpy# 删除packageconda remove -n python34 numpy# 查看当前环境下已安装的包conda list# 查看某个指定环境的已安装包conda list -n python34# 查找package信息conda search numpy# 安装packageconda install -n python34 numpy# 如果不用-n指定环境名称，则被安装在当前活跃环境# 也可以通过-c指定通过某个channel安装# 更新packageconda update -n python34 numpy# 删除packageconda remove -n python34 numpy### 前面已经提到，conda将conda、python等都视为package，因此，完全可以使用conda来管理conda和python的版本，例如# 更新conda，保持conda最新conda update conda# 更新anacondaconda update anaconda# 更新pythonconda update python# 假设当前环境是python 3.4, conda会将python升级为3.4.x系列的当前最新版本### 补充：如果创建新的python环境，比如3.4，运行### conda create -n python34 python=3.4### 之后，conda仅安装python 3.4相关的必须项，如python, pip等，如果希望该环境像默认环境那样，安装anaconda集合包，只需要：# 在当前环境下安装anaconda包集合conda install anaconda# 结合创建环境的命令，以上操作可以合并为conda create -n python34 python=3.4 anaconda# 也可以不用全部安装，根据需求安装自己需要的package即可# 在当前环境下安装anaconda包集合conda install anaconda# 结合创建环境的命令，以上操作可以合并为conda create -n python34 python=3.4 anaconda# 也可以不用全部安装，根据需求安装自己需要的package即可# 设置国内镜像### 如果需要安装很多packages，你会发现conda下载的速度经常很慢，因为Anaconda.org的服务器在国外。所幸的是，清华TUNA镜像源有Anaconda仓库的镜像，我们将其加入conda的配置即可：# 添加Anaconda的TUNA镜像conda config —add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/# TUNA的help中镜像地址加有引号，需要去掉# 设置搜索时显示通道地址conda config —set show_channel_urls yes# 添加Anaconda的TUNA镜像conda config —add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/# TUNA的help中镜像地址加有引号，需要去掉# 设置搜索时显示通道地址conda config —set show_channel_urls yes 执行完上述命令后，会生成~/.condarc(Linux/Mac)或C:UsersUSER_NAME.condarc文件，记录着我们对conda的配置，直接手动创建、编辑该文件是相同的效果。","link":"/posts/52525/"},{"title":"Linux终端的基本命令","text":"Linux终端入门手册 shell 提示符username@hostname:direction$ shell命令格式command [option] [arguments] 按一次tab补全文件名按两次tab补全命令单击右键粘贴 基本命令 帮助命令 man 查看man手册 info 查看info手册 —help 目录 根目录 / .代表目录自己 ..代表目录的父目录，对于根目录.和..都代表自己 pwd 查询当前目录路径 ～ 引用当前用户的主目录 绝对路径/home/hxy/hello.txt 相对路径./hello.txt 文件与目录相关命令 ls 显示目录内容 ls -la 列出所有文件，包括隐含文件 ls -dl 仅查看目录属性 ls -R 递归显示子目录的文件 ls 文件名/文件夹名 查看文件信息 ls -l 详细结果 详细结果：drwx------ 14 student student 409611...第一个字符表示文件类型：-普通文件 d目录 l符号链接 b块设备文件 c字符设备文件后面9个字符表示文件的访问权限： 第一组表示文件属主的权限 第二组表示同组用户的权限 第三组表示其他用户的权限各权限如下 r 读 w 写 x 执行，对于目录表示进入 cd 切换工作目录 cd .. 进入上一级目录 cd ~ 或 cd 进入用户主目录 mv [options] 源文件/文件夹 目标文件/文件夹 cp 复制文件或目录 cp -a 拷贝目录，保留一切链接和属性 cp -f 覆盖已经存在的目标文件而不提示 cp -R 递归复制目录下的所有字目录和文件 mkdir 创建一个目录 mkdir -m 对新建目录设置存取权限（chmod） mkdir -p 自动补全不存在的上级目录 rmdir 删除空目录 rmdir -p 递归删除目录 rm 删除 rm -r 递归删除（等同rmdir） rm -i 删除一个文件 rm -f 不询问，直接删除 file 确定文件类型 cat 链接或显示文件内容 带行数 cat -n 等价于nl tac 从最后一行开始显示文件内容 more/less head/tail touch 新建文件 nl 按输出行号的方式显示文件 ln 为一个文件在另一个位置建立符号链接 ln -s 目标 目录 软连接，一个指向源文件名的连接文件，类似快捷方式 ln 目标 目录 硬连接 类似指针 字符 grep 定位字符信息 wc 统计字符信息 sort 排序字符信息 打包/压缩文件 打包：把所有文件合并在一个tar文件里 压缩 使用gzip(tar.gz/tgz)或biz2(tar.bz2)压缩.gz比较快，压缩率不如bz2 -c 创建tar文件 -f将文件打包生成到一个文件 tar -cf new.tar ./home/se tar -xf new.tar 解包 对于zip格式：tar cvzf 打包 tar xvzf解包 对于biz2格式： tar cvjf 打包 tar xvjf解包 用户管理及网络设置GCC编译器gcc支持的源码格式：.c .cpp .m（Objective-C源程序） .i（预处理后的c文件） .ii（预处理后的c++文件） .s/.S（汇编语言源程序） .h（预处理器文件） .o（目标文件） gcc的基本使用单个源码 gcc hello.c -o hello 把hello.c编译成一个可执行程序hello（一次性完成四步） gcc hello.c不指定输出名，生成一个a.out 源文件到可执行文件的编译过程： 预处理 gcc -E hello.c -o hello.i 编译：将源代码编译成汇编代码 gcc -S hello.i -o hello.s 汇编：将汇编代码汇编成目标文件 gcc -c hello.s -o hello.o 链接：将目标代码和所需要库链成一个完整的应用程序 gcc hello.o -o hello gcc的结果输出于后缀名，只和输出参数有关 多个源码 一般先将源代码编译成目标代码，最后一次链接成可执行程序 对于有头文件在多个目录，需要在编译时多次使用-I参数加入头文件所在目录例如a.c需要用到/usr，当前目录/homegcc -I -I/usr -I/home -c a.c 对于多个源文件组成的程序。可以把多个文件在一句里编译，但建议不这样做，建议使用makefile脚本来调用gcc构造，见下一节gcc a.c b.c d.c -o test gcc的选项 宏macro -Dmacro gcc test.c -DPRINTF=printf -o test -Dmacro=defn gcc test.c -DNUM=10 -o test gcc -Wall a.c -o a打开所有编译警告 gcc -Wall -Werror a.c -o a将警告视作错误，出现任何警告就放弃编译 gcc -w禁止输出警告 gcc使用的第三方库gcc命令的参数详解 -x：设定文件名所使用的语言，使文件后缀名无效 gcc -x c hello.pig -c：只进行预处理,编译和汇编，即生成.o的obj文件 gcc -c hello.c -S：只进行预处理和编译，即把文件编译为.s汇编代码 gcc -S hello.c -E：只激活预处理。这个命令不会不生成文件, 我们需要把它重定向到一个输出文件里面 gcc -E hello.c &gt; pianoapan.txt -o：生成可执行文件 gcc -o hello hello.c -fno-asm -fno-strict-prototype -fthis-is-varialble -fcond-mismatch -funsigned-char 、-fno-signed-char、-fsigned-char 、-fno-unsigned-char -include file -imacros file b Makefilemake的调用 直接执行make，自动查找当前目录下名为makefile的文件，并自动从第一个target开始执行 如果makefile脚本名称不是缺省名称，使用-f参数来表示make -f hello.mk 如果需要make查找其他目录下的makefile，使用-C参数make -C /home 在makefile中以target表示不同的编译部分，可以在命令行直接写target名称，用于一个活多个target的编译make installmake target1 target2 makefile的格式makefile由由一组依赖关系和规则构成 每个依赖关系由一个目标（即将要创建的文件）和它依赖的源文件组成 规则描述了怎样从源文件创建出目标文件 规则也称为target 规则 目标名称：[依赖对象]&lt;tab&gt;命令列表 目标名称是需要创建的结果的名称 依赖对象表示创建这个目标之前必须预先创建的其他目标，可以是另一个规则的名称，也可以是基本文件的名称 命令列表表示为了创建这个目标，需要执行那些shell命令可以是一行或多行shell命令，每一行命令行的行首必须是一个tab 行首必须是tab不能是空格，否则makefile出错 如果命令行过长，可用\\分行，新行无需tab打头123456# 要想生成hello.o目标，必须先有hello.c，然后调用gcc编译生成hello.o，依赖对象hello.c可以省略hello.o: hello.c gcc -c hello.c -o hello.o# 要想生成执行程序hello，必须先执行规则hello.o，然后调用命令行gcc连接生成hellohello: hello.o gcc hello.o -o hello makefile里规则的前后顺序不太重要，实际调用顺序取决目标之间的依赖关系，因此make采用逆推的方式来判断和执行目标* 伪目标phony target：一般的目标最终是为了生成一个文件，但有一些目标可以不生成结果文件，只是为了调用命令或依赖对象，具体动作需要需要开发者自行编写 all 编译所有目标 clean 清楚项目生成的中间文件和最终生成文件 install 项目如何安装 uninstall 项目如何卸载 makefile基本结构makefile一般包含： 需要由make工具创建的项目，通常是目标文件和可执行文件，它们一般被称为target 要创建的目标依赖于哪些文件 创建每个目标时需要运行的的命令，命令之间用tab打头 通常包含的固定伪目标 #表示注释行1234567891011#Makefile for exp2main: main.o add.o del.o modify.o gcc -o main main.o add.o del.o modify.omain.o: main.c gcc -c main.cadd.o: add.c gcc -c add.cdel.o: del.c gcc -c del.cmodify.o: modify.c gcc -c modify.c makefile扩展用法 变量（宏）：利用简单的变量定义冗长的编译选项，引用时需要添加$符号1234567# Define macros for name of compiler CC = gcc# Define a macro for the CC flags CCFLAGS = -D_DEBUG -g -m486# A rule for building a object file test.o: test.c test.h $(CC) -c $(CCFLAGS) test.c makefile变量定义，=两边一定要有空格 makefile的变量定义要独立在规则之外，一般在最前 GNU make的预定义变量 $&lt; 第一个依赖文件的名称 $@ 目标的完整名称 $^ 所有的依赖文件，以空格分开，不包含重复的 AR 归档维护程序的名称，默认值ar ARFLAGS 归档维护程序的选项 AS 汇编程序的名称，默认值as ASGLAGS 汇编程序的选项 CC c编译器的名称，默认值cc CCFLAGS c编译器的选项 1234567891011#makefile2 for expmain: main.o add.o del.o modify.o gcc -o $@ $^main.o: main.c gcc -c $&lt;add.o: add.c gcc -c $&lt;del.o: del.c gcc -c $&lt;modify.o: modify.c gcc -c $&lt; 自动化变量使用12345#makefile2 for expmain: main.o add.o del.o modify.o gcc -o $@ $^.c.0: gcc -c $&lt; 隐含规则GNU make的一些内置的隐含规则定义了如何从不同依赖文件建立特定类型的目标文件 后缀规则suffix rule将一个具有某个后缀的文件转换为具有另一后缀的文件12.c.0: $(CC) $(CCFLAGS) -c -o $@ $&lt; 模式规则pattern rules在目标的前面多一个%，同时可用来定义目标和依赖文件之间的关系12%.o:%.c: $(CC) $(CCFLAGS) -c -o $@ $&lt; makefile目标编译如果不指定目标，make会默认第一个target规范的makefile文件有以下常见的几个目标： make all 编译所有目标 make clean 在编译结束后删除.o文件 make install 编译结束后将最终的可执行文件安装到系统的某一个位置12345678910#makefile for exampleexample: example.o add.o modify.o delete.o $(CC) -o $@ $^.c.o: $(CC) -c $&lt;all: exampleclean: all rm -f *.oinstall: clean cp example /usr/local/bin GDB调试器和调试方法gdb的使用为使程序能被调试，需要gcc编译时用-g选项为程序编译时添加调试信息gcc -g -o helloworld helloworld.c然后在命令行键入gdb并回车就可以运行了 gdb命令 file 装入想要调试的可执行文件。 kill 终止正在调试的程序。 list 列出产生执行文件的源代码的一部分。 next 执行一行源代码但不进入函数内部。 step 执行一行源代码而且进入函数内部。 run 执行当前被调试的程序。 c 继续运行程序。 quit 终止gdb。 watch 使你能监视一个变量的值而不管它何时被改变。 backtrace 栈跟踪，查出代码被谁调用。 print 查看变量的值。 make 使你能不退出gdb就可以重新产生可执行文件。 shell 使你能不离开gdb就执行UNIX shell命令。 whatis 显示变量或函数类型。 break 在代码里设断点，这将使程序执行到这里时被挂起。 break linenum 根据行号设置断点 break funcname 根据函数名设置断电 break filename:linenum/funcname 执行非当前源文件的某行或某函数的时候停止执行 break linenum/funcname if expr 根据条件停止程序执行 info break 显示当前断点清单，包括到达断点处的次数等。 info files 显示被调试文件的详细信息。 info func 显示所有的函数名称。 info local 显示当函数中的局部变量信息。 info prog 显示被调试程序的执行状态。 delete [n] 删除第n个断点。 disable[n] 关闭第n个断点。 enable[n] 开启第n个断点。 ptype 显示结构定义。 set variable 设置变量的值。 call name(args) 调用并执行名为name，参数为args的函数。 Finish 终止当前函数并输出返回值。 return value 停止当前函数并返回value给调用者。 GTK","link":"/posts/55266/"},{"title":"markdown进阶使用技巧","text":"markdown中的mermaid作图, html结合等进阶使用的handbook 页内跳转 两种方法究其根本都是md中html语法的应用 1.生成目录方法 123* [页内跳转](#link_in_page) * [1生成目录的方法](#link_in_page.1) * [2html标签实现](#link_in_page.2) 生成效果: 页内跳转 1.生成目录的方法 2.html标签实现 在正文中对应的地方, 加入章节标题对应id 1&lt;h2 id='link_in_page'&gt;页内跳转&lt;/h2&gt; 2.html标签实现 定义一个锚在跳转的目的地 &lt;span id = &quot;jumptoexample&quot;&gt;页内跳转&lt;/span&gt; 在要需要跳转的地方使用md语法的超链接 [ 点击跳转 ](#jumptoexample) 点击跳转","link":"/posts/64578/"},{"title":"mac快捷键和常用命令行","text":"mac常用命令行 隐藏文件 显示隐藏文件： 12defaults write com.apple.Finder AppleShowAllFiles YESKillAll Finder 不显示隐藏文件： 12defaults write com.apple.Finder AppleShowAllFiles NOKillAll Finder 快捷键方式：command+shift+. 截图 修改截图默认文件名 12defaults write com.apple.screencapture name &quot;Screenshot&quot;killall SystemUIServer 更换默认截图路径 12defaults write com.apple.screencapture location ~/Desktop/屏幕截图killall SystemUIServer 去掉窗口截图的阴影 12defaults write com.apple.screencapture disable-shadow -bool truekillall SystemUIServer","link":"/posts/8410/"},{"title":"VPS和Shadowsocks配置","text":"VPS服务器的创建、Shadowsocks的配置 最新文章ss to v2ray中，建议更换ss为v2ray 参考网址 Jerryzhou-shadowsocks的基本安装配置 itrhs-进阶使用 1 注册和创建Droplets 在此跳过VPS的注册和购买过程，目前可以使用的VPS服务商中比较有名的，国外有Vurtlr、Linode、DigitalOcean，国内有阿里云、腾讯云，具体对比见 可以免费换的VPS商家盘点 笔者使用的是Digital Ocean，附上优惠码：https://m.do.co/c/438f7c8cc2dd，当时注册的时候据说送50刀，但当时耽搁了开始使用的时间，隔了一个月没用就过期了 系统是 CentOS 7 x64 - Enable IPV6 非CentOS7可能导致后续出现python等缺失 本地创建SSH key（已有则跳过此步骤） ssh key是让我们每次登陆的时候无需输入密码，通过本机机器码验证的方式 123456789# 查看本地的SSH keycd ~/.sshls *.pub# 创建新的SSH keyssh-keygen -t rsa -C \"email@example.com\"# 将key加入用户列表，否则每次都会需要验证电脑登录密码ssh-add -k /Users/m/.ssh/id_rsa# 复制本地公钥cat ~/.ssh/id_rsa.pub 将公钥添加到DO账号Security中 这个时候使用本机公钥即可远程登录服务器，当然不配置也可以使用密码登录的方式 1ssh root@IP地址 修改密钥登陆为密码登陆的方法： 12# 编辑ssh配置文件 vi /etc/ssh/sshd_config 找到以下字段，并修改为： 12PermitRootLogin yes # 允许根用户登录PasswordAuthentication no # 打开密码登录 重启ssh服务service sshd restart 2 Shadowsocks CentOS7自带python2.7，所以直接安装pip 12yum -y install pippip install shadowsocks 创建配置文件 1vim /etc/shadowsocks.json 配置文件内容： 123456789101112131415161718192021222324252627282930313233343536373839//普通配置{ \"server\":\"服务器ip地址\", \"server_port\":8388, \"local_address\": \"127.0.0.1\", \"local_port\":1080, \"password\":\"你设置的密码\", \"timeout\":300, \"method\":\"aes-256-cfb\", \"fast_open\": false}// 多端口配置// 即把server_port和password两项替换为port_password{ \"server\": \"服务器ip地址\", \"server_ipv6\": \"::\", \"local_address\": \"127.0.0.1\", \"local_port\": 1081, \"port_password\": { \"8686\":\"你设置的密码\", \"8687\":\"你设置的密码\", \"8688\":\"你设置的密码\", \"8689\":\"你设置的密码\", \"8690\":\"你设置的密码\" }, \"timeout\": 120, \"udp_timeout\": 60, \"method\": \"aes-256-cfb\", \"protocol\": \"auth_sha1_v4_compatible\", \"protocol_param\": \"\", \"obfs\": \"http_simple_compatible\", \"obfs_param\": \"\", \"dns_ipv6\": false, \"connect_verbose_info\": 1, \"redirect\": \"\", \"fast_open\": false, \"workers\": 1} ssh服务器启动 1234567ssserver -c /etc/shadowsocks.json# 或者在后台运行ssserver -c /etc/shadowsocks.json -d startssserver -c /etc/shadowsocks.json -d stop# 日志ssserver -c /etc/shadowsocks.json --log-file /tmp/ss.log -d starttail -f /tmp/ss.log 附加：vim的安装和配置 安装vim 1yum install vim 配置vim 1vi ~/.vimrc vim配置文件参考 123456789101112131415161718192021222324252627282930313233\" Configuration file for vimset modelines=0 \" CVE-2007-2438\" Normally we use vim-extensions. If you want true vi-compatibility\" remove change the following statementsset nocompatible \" Use Vim defaults instead of 100% vi compatibilityset backspace=2 \" more powerful backspacing\" Don't write backup file if vim is being called by \"crontab -e\"au BufWrite /private/tmp/crontab.* set nowritebackup nobackup\" Don't write backup file if vim is being called by \"chpass\"au BufWrite /private/etc/pw.* set nowritebackup nobackuplet skip_defaults_vim=0syntax onautocmd InsertLeave * se noculautocmd InsertEnter * se culset tabstop=4set softtabstop=4set shiftwidth=4set numbercolorscheme pabloset rulerset scrolloff=3set rtp+=/usr/local/opt/fzf 3 速度升级和安全性 配置防火墙（可能导致后续安装锐速服务后出现模块冲突，建议最后再打开防火墙） yum install firewalld 123452. 配置防火墙文件： ```bash vi /etc/firewalld/zones/public.xml 一个端口对应两个 123456789101112131415161718 &lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt; &lt;zone&gt;&lt;short&gt;Public&lt;/short&gt;&lt;service name=\"dhcpv6-client\"/&gt;&lt;service name=\"ssh\"/&gt;&lt;port protocol=\"tcp\" port=\"8686\"/&gt;&lt;port protocol=\"udp\" port=\"8686\"/&gt;&lt;port protocol=\"tcp\" port=\"8687\"/&gt;&lt;port protocol=\"udp\" port=\"8687\"/&gt;&lt;port protocol=\"tcp\" port=\"8688\"/&gt;&lt;port protocol=\"udp\" port=\"8688\"/&gt;&lt;port protocol=\"tcp\" port=\"8689\"/&gt;&lt;port protocol=\"udp\" port=\"8689\"/&gt;&lt;port protocol=\"tcp\" port=\"8690\"/&gt;&lt;port protocol=\"udp\" port=\"8690\"/&gt;&lt;port protocol=\"tcp\" port=\"8691\"/&gt;&lt;port protocol=\"udp\" port=\"8691\"/&gt;&lt;/zone&gt; 重启shadowsocks，重启防火墙 12# 重启防火墙systemctl restart firewalld.service firewalld的基本使用 启动： systemctl start firewalld 关闭： systemctl stop firewalld 查看状态： systemctl status firewalld 开机禁用 ：systemctl disable firewalld 开机启用 ：systemctl enable firewalld 查看开放的端口：firewall-cmd --list-ports 添加端口：firewall-cmd --zone=public --add-port=59008/tcp --permanent（–permanent永久生效，没有此参数重启后失效) 查看所有被占用的端口 netstat -tunlp 下载锐速服务（建议直接使用下一条四合一脚本） 12345678910# 对于centOS7 需要先下载需要的固件20140911 rpm -ivh ftp://ftp.pbone.net/mirror/ftp.scientificlinux.org/linux/scientific/7.0/x86_64/updates/security/linux-firmware-20140911-0.1.git365e80c.el7.noarch.rpm# 更换内核wget --no-check-certificate -O rskernel.sh https://raw.githubusercontent.com/hombo125/doubi/master/rskernel.sh &amp;&amp; bash rskernel.sh# 内核更换完后显示Success后需要重新连接到服务器ssh root@IP地址# 查看当前内核版本uname -r# 下载锐速，一路回车安装yum install net-tools -y &amp;&amp; wget --no-check-certificate -O appex.sh https://raw.githubusercontent.com/0oVicero0/serverSpeeder_Install/master/appex.sh &amp;&amp; bash appex.sh install bbr 原版/魔改/plus+锐速 四合一脚本 123456789101112# 下载脚本wget \"https://github.com/cx9208/Linux-NetSpeed/raw/master/tcp.sh\" &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh# 如果证书错误的话apt-get -y install ca-certificatesyum -y install ca-certificates# 1-3中选择切换内核，自动重启，如果出现是否删除Configuring image,选择no# 调用脚本./tcp.sh# 在4-8中选择要开的加速 \"1. 安装 BBR/BBR魔改版内核\" 对应4,5,6（原版，魔改，暴力魔改） \"2. 安装 BBRplus版内核 \" 对应7（plus） \"3. 安装 Lotserver(锐速)内核\" 对应8（锐速） 服务器测速 speedtest 12345678# 断链接wget -qO- git.io/superbench.sh | bash# 使用参数wget -qO- git.io/superbench.sh | bash -s infowget -qO- git.io/superbench.sh | bash -s iowget -qO- git.io/superbench.sh | bash -s speedwget -qO- git.io/superbench.sh | bash -s fastwget -qO- git.io/superbench.sh | bash -s share","link":"/posts/9931/"},{"title":"Hexo博客搭建入门","text":"使用基于Nodejs的Hexo博客框架, 结合github.io页面, 快速搭建个人博客并发布 0 先决条件 GitHub账号 1 工具准备1 GITHUB仓库创建​ 创建新repository，名为username.github.io(username与github用户名一致) 2 安装相关工具 安装node管理工具nvm 12345# 使用brew安装brew install nvm# 添加进终端配置文件（.zshrc或.bash_profile)export NVM_DIR=~/.nvm[ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" 此处有个坑: nvm官方并不建议使用brew安装 Homebrew installation is not supported. If you have issues with homebrew-installed nvm, please brew uninstall it, and install it using the instructions below, before filing an issue. 如果使用Homebrew安装，因为安装路径等原因, 在.nvm中会缺少nvm-exec和nvm.sh两个文件。导致每次启动终端都需要输入source $(brew --prefix nvm)/nvm.sh才能使当前终端使用nvm命令 解决方法有2 简单粗暴：在.zshrc（终端配置文件）中加入source $(brew --prefix nvm)/nvm.sh 曲线救国：(注意此方法curl命令可能被墙, 具体见nvm项目github) 卸载使用brew安装的nvmbrew uninstall nvm 使用curl命令下载 1curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.2/install.sh | bash 终端配置文件加入 123export NVM_DIR=\"$HOME/.nvm\"[ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" # This loads nvm[ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion 安装nodejs 1nvm install stable 网上很多过期教程会建议使用 nvm install 4 , nvm install 6 , 实际安装后, node版本在7以下的都会抛出异常, 建议一步到位安装最新稳定版node nvm/npm常用命令: 1234567891011# 切换nvm版本至 &lt;number&gt;开头的默认版本nvm use &lt;number&gt; #设置默认 node 版本为 0.12.7nvm alias default 0.12.7 # 使用.nvmrc文件配置项目所使用的node版本cd &lt;项目根目录&gt; #进入项目根目录echo &lt;number&gt; &gt; .nvmrc #添加 .nvmrc 文件nvm use #无需指定版本号，会自动使用 .nvmrc 文件中配置的版本node -v #查看 node 是否切换为对应版本#安装 &lt;module-name&gt; 模块至全局目录，安装完成的路径是 /Users/&lt;username&gt;/.nvm/versions/node/&lt;nvm-version&gt;/lib/&lt;module-name&gt;npm install -g &lt;module-name&gt; nvm与n的区别 node 版本管理工具还有一个是 TJ 大神的 n 命令，n 命令是作为一个 node 的模块而存在，而 nvm 是一个独立于 node/npm 的外部 shell 脚本，因此 n 命令相比 nvm 更加局限。 由于 npm 安装的模块路径均为 /usr/local/lib/node_modules ，当使用 n 切换不同的 node 版本时，实际上会共用全局的 node/npm 目录。 因此不能很好的满足『按不同 node 版本使用不同全局 node 模块』的需求。 安装Hexo 1sudo npm install hexo-cli -g 2 hexo的使用入门 创建博客和基础配置 12hexo init username.github.io # 博客根目录&lt;folder_name&gt;cd username.github.io 更改博客根目录下的_config.yml文件 1234567title:author:language: zh-Hans #中文theme: landscapedeploy: type: git repo: https://github.com/username/username.github.io.git 更换主题 主题测评见文章hexo的主题比较 hexo初始化中自带landscape主题 12# 此处以next主题为例git clone https://github.com/iissnan/hexo-theme-next themes/next 进入themes/next, 打开_config.yml, 按照文件中的说明即可对主题进行基础配置 同时更改博客根目录中_config.yml文件的theme: next 写文章 博客根目录username.github.io下的source文件夹保存所有博客, 默认使用md语法 hexo写作命令 1hexo new [layout] &lt;title&gt; 12345678910---title: Hexo博客搭建入门date: 2020-02-16tags: hexo jscategories: - Code - Guidekeywords: hexo js 前端 博客---Hello World! 测试hexo s 安装使用hexo-deployer-git](https://link.jianshu.com/?t=https://github.com/hexojs/hexo-deployer-git)自动部署发布工具 12npm install hexo-deployer-git --savehexo clean &amp;&amp; hexo g &amp;&amp; hexo d hexo的使用进阶基本命令 hexo init：新建一个网站 hexo new [layout] --option &lt;titile&gt; ：新建一个layout的文章，如果标题有空格，使用引号括起来 -p 自定义新文章的路径 -r 替换同名文章 -s 作为新文章的文件名和发布后的url hexo generate生成静态文件(只生成有改动的文件) -d生成后立刻部署 -w 监视文件变动 -b 抛出生成过程中的异常 -f 强制重新生成全部文件 -c 最大同时生成文件的数量 hexo publish [layout] &lt;filename&gt; 发表草稿 hexo server 打开本地服务器 hexo deploy 部署 hexo render &lt;file1&gt; [file2] 渲染文件 -o设置输出路径 写作 layout：post/page/draft 如果你不想你的文章被处理，你可以将 Front-Matter 中的layout: 设为 false 。 title：在_config.yaml中编辑参数改变默认名称 scaffold：根须scaffold文件夹内对应的文件来建立文件 Font-matter layout：布局 title：标题/文件名 date：建立日期 update：更新日期 comments：开启文章的评论功能 tags：标签 categories：分类 如果需要为文章添加多个分类 1234categories:- [Diary, PlayStation]- [Diary, Games]- [Life] permalink：覆盖网址 keywords：仅用于meta标签和Open Graph的关键词 标签插件 并不建议过多使用这些标签，这些标签是hexo的私有语法，迁移是会有不便，建议还是多使用md语法 hexo官网关于个别标签的演示并不完整，icarus主题的文档中有不同插件使用的Demo 引用块(quote) 等同md语法的&lt; 123{% blockquote [author[, source]] [link] [source_link_title] %}content{% endblockquote %} 代码块(code) 等同md语法的``` 123{% codeblock [title] [lang:language] [url] [link text] [additional options] %}code snippet{% endcodeblock %} line_number:flase highlight:true first_line:13 行号从第几开始 mark:1,4-7 下划线特定行，即第1行和4到7行 wrap:true Pull Quote 123{% pullquote [class] %}content{% endpullquote %} jsFiddle 1{% jsfiddle shorttag [tabs] [skin] [width] [height] %} Gist(一般短代码直接插入markdown，长代码才用gist) 1{% gist gist_id [filename] %} iframe 1{% iframe url [width] [height] %} Image 1{% img [class names] /path/to/image [width] [height] '\"title text\" \"alt text\"' %} Link 1{% link text url [external] [title] %} Include 1{% include_code [title] [lang:language] [from:line] [to:line] path/to/file %} Youtube/Vimeo 12{% youtube video_id %}{% vimeo video_id %} 引用文章(我一般是当做直接引用链接fffff) 12{% post_path filename %}{% post_link filename [title] [escape] %} 引用文章的资源(关于资源文件夹的设置见本文图片部分 123{% asset_path filename %}{% asset_img filename [title] %}{% asset_link filename [title] [escape] %} Raw 插入Swig标签 123{% raw %}content{% endraw %} 文章摘要：在&lt;!--more--&gt; 之前的文字 可能会被Font Matter中的excerpt部分覆盖(需要插件支持) 图片 资源文件夹 : 最简单的方法就是将它们放在 source/images 文件夹中。然后通过类似于 ![](/images/image.jpg) 的方法访问它们。 组织化资源管理方式 : 通过将 config.yml 文件中的 post_asset_folder 选项设为 true 来打开, 当资源文件管理功能打开后，Hexo将会在你每一次通过 hexo new [layout] 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们 1![图片名称](图片名称.jpg) 需要注意, 使用md时,在首页显示会出现错误, 使用标签插件可以解决 1{% asset_img 图片名称.jpg This is an example image %} tips 在typora的设置中进行以下修改可以与hexo同步： 组织化资源管理的两种方式都会使图片失去本地编辑器上的可读性 3. 实际使用中会遇到部分主题对标签插件渲染出现莫名其妙的错误(vexo)，或者主题不支持(terminal)，所以除非需要在首页的展示缩略图，建议使用markdown语法的方式。","link":"/posts/2727/"},{"title":"hexo的主题比较","text":"hexo各个主题的比较, 以及部分主题的修改 我的需求 目的：记录开发中遇到的坑，形成自己的handbook 功能： 🔍站内搜索LeanCloud统计 🤥 Valine的评论服务 较为友好的代码高亮 有展示GitHub project（接入GitHub的API）的project页面 seo支持 界面： 首页tagCloud和categories的Widget 首页的index展示文章的tag和category标签 单篇博文内有随页面变化的目录widget archive展示时间轴 各个theme评价基于jade ( pug )开发的主题 Jade 是一个高性能的模板引擎，它深受 Haml 影响，它是用 JavaScript 实现的，并且可以供 Node 使用，后来由于商标的原因，改为Pug 以下列举的主题都仍然使用hexo-renderer-jade插件，npm会提示插件已被废弃，运行时会显示错误提示。首先要替换hexo-renderer-jade插件为hexo-renderer-pug，下载命令为npm install hexo-renderer-pug --save；然后将主题layout文件夹中的所有.jade文件替换为.pug文件 入门指南：[pug中文文档](https://pugjs.org/zh-cn/api/getting-started.html) Apollo 博客首页博客归档页 界面干净，多个theme都基于apollo开发，如Gandalfr Hermes artemis bubuzou pandollo 缺点: 功能缺乏，需要自己接入评论、目录、搜索、Widget等功能； bubuzou 博客首页博文底部 基于apollo开发, 补充大量apollo缺乏的功能，如评论、目录、搜索、Widget；评论支持Valine评论； 首页 css页面适配存在缺陷（缩放时borden过小），代码高亮有缺陷，个别博文底部不会出现评论窗口(奇奇怪怪的bug) 实际使用的时候发现leancloud的访问量统计功能有缺点，留个坑； 1234567p.visit i(class=&quot;article-timer&quot;, data-identity=item.path) span 次访问 if (is_home()) i(data-hk-page='http://anne416wu.github.io'+url_for(item.path)) - else i(data-hk-page=&quot;current&quot;) Gandalfr 不放图了，这玩意儿bug挺多。有意思的是作者写了个tagCloud的辅助插件，给TagCloud加上了动画效果。界面上较bubuzou更贴近apollo。 有时间的可以把Gandalfr的界面和bubuzou的功能结合一下。 基于ejs开发的主题 ejs是一套简单的模板语言，利用普通的 JavaScript 代码生成 HTML 页面，相比上面使用jade，修改更为方便。个人体验感觉ejs性能的确不如jade。 Vexo博客首页博文开头归档页项目页 满足对界面的一切幻想(对界面的幻想都是这个主题惯出来的)，支持多种代码高亮 缺点：未接入搜索功能，仅支持gitment评论，无首页CLoudTag的Widget等 本地运行存在bug。使用hexo s预览时，如果文章资源读取出现错误，整个博客页面会显示空白 Cactus 博客首页博文开头归档页 界面干净，支持多种代码高亮 因为是国外开发的，对本地化的支持较少； &lt;–未完待续–&gt; 基于Swig开发的主题","link":"/posts/27751/"},{"title":"编译原理与设计-Lab1-语言认知实验","text":"分别使用 C/C++、Java、Python 和 Haskell 实现快速排序和归并排序算法，对采用这几种语言实现的编程效率，程序的规模，程序的运行效率进行对比分析。 1 实验目的和内容 实验目的：了解程序设计语言的发展历史，了解不同程序设计语言的各自特点;感受编 译执行和解释执行两种不同的执行方式，初步体验语言对编译器设计的影响，为 后续编译程序的设计和开发奠定良好的基础。 实验内容： 分别使用 C/C++、Java、Python 和 Haskell 实现快速排序算法和归并排序，对采用这几种语言实现的编程效率，程序的规模，程序的运行效率进行对比分析。 实验说明：实验使用电脑参数如下 2 实验的具体过程和步骤 实验分三组： 普通情况(50000个范围在1~100000的不重复数)下不同语言的归并排序和快速排序 最坏情况： 小规模组(1000-&gt;1逆序排列) 大规模组(10000-&gt;1逆序排列) 快速排序的算法采用三数取最小数的算法，平均时间复杂度 $ O(nlogn) $ ，最坏时间复杂度 $ O(n^2) $ 归并排序无论最好最坏情况，时间复杂度均为 $ O(nlog_2n) $ 不同语言所使用的的算法完全一致，时间函数分别使用各语言提供的库函数 C语言 编译器版本及运行环境 123 $ gcc --version Apple clang version 11.0.0 (clang-1100.0.33.17)Target: x86_64-apple-darwin19.3.0 源代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/time.h&gt;#define N 1000 //50000为实验1规模，10000为实验2-1规模，1000为实验2-2规模#define O 2 //1为装填out.txt中的数据，2为装填逆序数组//归并函数void Merge(int *num, int start, int mid, int end){ int *temp = (int *)malloc((end-start+1) * sizeof(int)); int i = start; int j = mid + 1; int k = 0; while (i &lt;= mid &amp;&amp; j &lt;= end){ if (num[i] &lt;= num[j]){ temp[k++] = num[i++]; } else { temp[k++] = num[j++]; } } while (i &lt;= mid){ temp[k++] = num[i++]; } while (j &lt;= end){ temp[k++] = num[j++]; } for (i = 0; i &lt; k; i++){ num[start + i] = temp[i]; } free(temp);}//归并排序void MergeSort_UptoDown(int *num, int start, int end){ int mid = start + (end - start) / 2; if (start &gt;= end) { return; } MergeSort_UptoDown(num, start, mid); MergeSort_UptoDown(num, mid + 1, end); Merge(num, start, mid, end);}//分解函数int partition(int arr[], int low, int high){ int key; key = arr[low]; while(low&lt;high){ while(low &lt;high &amp;&amp; arr[high]&gt;= key ) high--; if(low&lt;high) arr[low++] = arr[high]; while( low&lt;high &amp;&amp; arr[low]&lt;=key ) low++; if(low&lt;high) arr[high--] = arr[low]; } arr[low] = key; return low;}//快速排序void quick_sort(int arr[], int start, int end){ int pos; if (start&lt;end){ pos = partition(arr, start, end); quick_sort(arr,start,pos-1); quick_sort(arr,pos+1,end); } return;}//装填函数int fill(int arr[]){ if(O==1){ int cnt = 0; FILE *fp = NULL; fp = fopen(\"/Users/apple/Downloads/out.txt\",\"r\"); char buff[10]; while(fscanf(fp,\"%s\",buff)!=EOF){ arr[cnt++]=atoi(buff); } return cnt; } else{ for (int i = 0; i &lt; N; ++i) { arr[i] = N - i; } return N; }}int main(){ int arr[N+1]; int num = fill(arr); struct timeval begintime,endtime; gettimeofday(&amp;begintime, NULL); quick_sort(arr , 0 , num-1); gettimeofday(&amp;endtime, NULL); printf(\"Size-%d / \", num); printf(\"Qsort-C Running Time : %ld ms\\n\",1000*(endtime.tv_sec-begintime.tv_sec)+(endtime.tv_usec-begintime.tv_usec)/1000); num = fill(arr); gettimeofday(&amp;begintime, NULL); MergeSort_UptoDown(arr , 0 , num-1); gettimeofday(&amp;endtime, NULL); printf(\"Size-%d / \", num); printf(\"Mergesort-C Running Time : %ld ms\\n\",1000*(endtime.tv_sec-begintime.tv_sec)+(endtime.tv_usec-begintime.tv_usec)/1000);} 使用gcc编译器生成可执行文件： 1gcc -o lab1_c lab1.c 在终端运行可执行文件6次 1/.lab1_c Java 编译器版本及运行环境 123456 $ Javac --version javac 10.0.2 $ java --version openjdk 10.0.2 2018-07-17 OpenJDK Runtime Environment 18.3 (build 10.0.2+13)OpenJDK 64-Bit Server VM 18.3 (build 10.0.2+13, mixed mode) 源代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111import java.io.*;public class Lab1 { static int O = 2; //1为装填out.txt中的数据，2为装填逆序数组 static int N = 10000; //50000为实验1规模，10000为实验2-1规模，1000为实验2-2规模 public static void fill(int[] arr){ if (O==1) { int cnt =0; String pathname = \"/Users/apple/Downloads/out.txt\"; try (FileReader reader = new FileReader(pathname); BufferedReader br = new BufferedReader(reader) ){ String line; while ((line = br.readLine()) != null) { arr[cnt++]=Integer.parseInt(line); } }catch (IOException e) { e.printStackTrace(); } } else{ for (int i=0; i&lt;N; i++) { arr[i] = N-i; } } } public static void main(String[] args){ print5(); } public static void print5(){ int[] arr = new int[N]; fill(arr); long t = System.currentTimeMillis(); // System.out.println(arr[0]+\" \"+arr[N/2]+\" \"+arr[N-1]); quick_sort(arr,0 , N-1); // System.out.println(arr[0]+\" \"+arr[N/2]+\" \"+arr[N-1]); System.out.println(\"QSort-Size-\"+N+\" / Java Running time : \"+(System.currentTimeMillis()-t)+\" ms\"); fill(arr); // System.out.println(arr[0]+\" \"+arr[N/2]+\" \"+arr[N-1]); t = System.currentTimeMillis(); m_sort(arr,0 , N-1); // System.out.println(arr[0]+\" \"+arr[N/2]+\" \"+arr[N-1]); System.out.println(\"MergeSort-Size-\"+N+\" / Java Running time : \"+(System.currentTimeMillis()-t)+\" ms\"); } //分解函数 public static int partition (int []arr, int low, int high){ int key; key = arr[low]; while(low&lt;high){ while(low &lt;high &amp;&amp; arr[high]&gt;= key ) high--; if(low&lt;high) arr[low++] = arr[high]; while( low&lt;high &amp;&amp; arr[low]&lt;=key ) low++; if(low&lt;high) arr[high--] = arr[low]; } arr[low] = key; return low; } //快速排序 public static void quick_sort(int []arr, int start, int end){ int pos; if (start&lt;end){ pos = partition(arr, start, end); quick_sort(arr,start,pos-1); quick_sort(arr,pos+1,end); } return; } //归并排序 public static int[] m_sort(int[] a,int low,int high){ int mid = (low+high)/2; if(low&lt;high){ m_sort(a,low,mid); m_sort(a,mid+1,high); //左右归并 merge(a,low,mid,high); } return a; } //合并函数 public static void merge(int[] a, int low, int mid, int high) { int[] temp = new int[high-low+1]; int i= low; int j = mid+1; int k=0; // 把较小的数先移到新数组中 while(i&lt;=mid &amp;&amp; j&lt;=high){ if(a[i]&lt;a[j]){ temp[k++] = a[i++]; }else{ temp[k++] = a[j++]; } } // 把左边剩余的数移入数组 while(i&lt;=mid){ temp[k++] = a[i++]; } // 把右边边剩余的数移入数组 while(j&lt;=high){ temp[k++] = a[j++]; } // 把新数组中的数覆盖nums数组 for(int x=0;x&lt;temp.length;x++){ a[x+low] = temp[x]; } }} 使用java编译器(javac.exe)编译为字节码文件(.class) 1javac Lab1.java 运行生成的字节码文件6次 1java Lab1 python 解释器版本 12$ python --versionPython 2.7.16 源代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import timeimport syssys.setrecursionlimit(100000)O = 1 //1为装填out.txt中的数据，2为装填逆序数组N = 50000 //50000为实验1规模，10000为实验2-1规模，1000为实验2-2规def merge(arr, l, m, r): n1 = m - l + 1 n2 = r- m L = [0] * (n1) R = [0] * (n2) for i in range(0 , n1): L[i] = arr[l + i] for j in range(0 , n2): R[j] = arr[m + 1 + j] i=0 j=0 k=l while i &lt; n1 and j &lt; n2 : if L[i] &lt;= R[j]: arr[k] = L[i] i += 1 else: arr[k] = R[j] j += 1 k += 1 while i &lt; n1: arr[k] = L[i] i += 1 k += 1 while j &lt; n2: arr[k] = R[j] j += 1 k += 1 def mergeSort(arr,l,r): if l &lt; r: m = int((l+(r-1))/2) mergeSort(arr, l, m) mergeSort(arr, m+1, r) merge(arr, l, m, r) def partition(arr,low,high): key = arr[low] while(low&lt;high): while low&lt;high and arr[high] &gt;= key: high-=1 if low&lt;high: arr[low] = arr[high] low+=1 while low&lt;high and arr[low]&lt;=key: low+=1 if low&lt;high: arr[high] = arr[low] high -= 1 arr[low] = key return lowdef q_sort(arr,start,end): if start&lt;end: pos = partition(arr,start,end) q_sort(arr,start,pos-1) q_sort(arr,pos+1,end) return arrdef quick_sort(arr): return q_sort(arr,0,len(arr)-1)def do(): if(O==1) arr=[] #直接使用out.txt内数据初始化 else for x in xrange(1,N): arr[i]=N-x; begintime=time.time() quick_sort(arr) endtime = time.time() Running_time = (endtime-begintime)*1000 print(\"Qsort-python Running time : %f ms\"%Running_time) begintime=time.time() mergeSort(arr,0,len(arr)-1) endtime = time.time() Running_time = (endtime-begintime)*1000 print(\"Msort-python Running time : %f ms\"%Running_time)arr = [0]*Ndo() 在终端运行6次 1python lab1.py Haskell 解释器版本 12$ runhaskell --versionrunghc 8.8.2 源代码 12345678910111213141516171819202122232425262728293031323334353637383940import Text.Printfimport Control.Exceptionimport System.CPUTimemsort :: (Ord a) =&gt; [a] -&gt; [a]msort [] = []msort [x] = [x]msort xs = merge (msort xs1) (msort xs2) where k = (length xs) `div` 2 xs1 = take k xs xs2 = drop k xs merge :: (Ord a) =&gt; [a] -&gt; [a] -&gt; [a] merge [] b = b merge a [] = a merge a@(x:xs) b@(y:ys) | x &gt;= y = x:(merge xs b) | otherwise = y:(merge a ys)qsort :: (Ord a) =&gt; [a] -&gt; [a]qsort [] = []qsort (x:xs) = qsort [i | i &lt;- xs, i &gt;= x] ++ [x] ++ qsort [i | i &lt;- xs, i &lt; x]main=do start &lt;- getCPUTime let list =msort [] --实验1直接填入out.txt中数组，实验2-1为[1..1000]，实验2.2为[1..10000] let a = maximum list printf \"Size %d \"(a::Int) end &lt;- getCPUTime let diff = (fromIntegral (end - start)) / (10^9) printf \"qsort Haskell Running time: %0.3f ms\\n\" (diff :: Double) start &lt;- getCPUTime let list =qsort [] --实验1直接填入out.txt中数组，实验2-1为[1..1000]，实验2.2为[1..10000] let a = maximum list printf \"Size %d \"(a::Int) end &lt;- getCPUTime let diff = (fromIntegral (start - end)) / (10^9) printf \"msort Haskell Running time: %0.3f ms\\n\" (diff :: Double) 在终端运行6次 1runhaskell lab1.hs 3 运行效果截图1 常规组 50000个范围在1~1000000的不重复数 C 快速排序平均运行时间：6.00 ms 归并排序平均运行时间：13.33 ms JAVA 快速排序平均运行时间：14.00 ms 归并排序平均运行时间：16.33 ms python 快速排序平均运行时间：88.26 ms 归并排序平均运行时间：244.45 ms Haskell 因为笔者失误，此处Size应为50000，msort和qsort对应时间输出交换，即第一行为qsort运行时间，第二行为msort运行时间 快速排序平均运行时间：504.93 ms 归并排序平均运行时间：416.71 ms 2-1 小规模最坏数据 对逆序数组[1000,999,998,997,996,995,…,4,3,2,1]进行升序排列 C 快速排序平均运行时间：1 ms 归并排序平均运行时间：0 ms Java 快速排序平均运行时间：3.5 ms 归并排序平均运行时间：0.83 ms python 快速排序平均运行时间：26.24 ms 归并排序平均运行时间：3.51 ms Haskell 因为笔者失误，msort和qsort对应时间输出交换，即第一行为qsort运行时间，第二行为msort运行时间 快速排序平均运行时间：309.12 ms 归并排序平均运行时间：3.285 ms 2-2大规模最坏数据 对逆序排列[10000,9999,9998,9997,9996,9995,…,4,3,2,1]进行升序排列 因为Haskell较易生成正序列表，所以对于Haskell对正序排列[1,2,3,4…9999,10000]进行降序排列 C 快速排序平均运行时间：97.17 ms 归并排序平均运行时间：1.6 ms Java 快速排序平均运行时间：45.67 ms 归并排序平均运行时间：4.67 ms Python 快速排序平均运行时间：2595.45 ms -&gt; 2.6s 归并排序平均运行时间：41.71 ms Haskell 因为笔者失误，msort和qsort对应时间输出交换，即第一行实为qsort运行时间，第二行为msort运行时间 快速排序平均运行时间：31378.91 ms -&gt; 31.4s 归并排序平均运行时间：38.00 ms 4 语言易用性和程序规模对比分析1 语言易用性1 学习难度Python&lt;=Java&lt;=C&lt;&lt;Haskell 语言 难度分析 C C作为大多数人编程的入门语言，先声夺人，字符串处理文件处理数组初始化等等基础操作，大多时候我都更习惯c的写法。链表与指针和内存管理是C的一大难以逾越的障碍 Java Java的语法大致类似C/C++，并且没有C中令人头疼的链表指针和内存操作，有自动内存管理，个人认为学过C再加上对面向对象的理解是非常容易上手Java的 Python Python近年被广泛推崇为儿童编程的入门语言，不一定说明它很简单，但至少说明它入门容易。Python中缩进作为格式化使得程序总体更简洁，但也使得在大项目中它的可维护性降低。Python更适合于小型项目，或者玩具，例如跑一个CNN。 Haskell 习惯了命令式语言，面对Haskell这样的纯函数式语言会陷入完全的不知所措。它是一种不同的概念、一种新的语言范式。需要用与我们的习惯所不同的方式开发应用，不同的方式组织应用，不同的方式扩展应用 2 语言的编程效率个人认为编程分为两部分：初始编码+Debug 对于几种主流语言编程效率的普遍看法认为，python是效率最高的，C次之，Java最为啰嗦繁琐，而函数式编程语言较少用于工程。但我个人的经历里，不同语言在不同项目规模下各有所长。大型项目大多基于Java的相关框架，如果开发一个移动互联应用(上万行)，Java几乎可以说是没有敌手，它的啰嗦和繁琐减小了奇奇怪怪的bug发生的可能性，而在Java下继续前进还有Korlin，Swift等专门为应用开发而设计的语言。C/C++适合于开发小型项目(几千行)，比如小游戏或者解释器，使用C开发能够在某种程度上方便开发者最大程度提升程序的运行效率。至于Python，个人认为Python适合千行以内的代码规模，目前的学习中使用到Python的地方主要是人工智能和知识工程等课程，一个神经网络大致也就一百行代码，Python的相关库Numpy和TensorFlow在神经网络的应用中已经非常成熟。尽管Python在初始编码阶段能优雅简洁的一行代码完成一个复杂的功能，但在debug阶段Python也能让人一个头有两个大。使用Python中稍不注意就会有缩进造成的bug，怎么检查都难以寻觅其踪迹，可想如果代码规模稍大，该有多么头疼。 至于函数式编程，其思想和命令式编程有很大的不同。有人说，大部分人第一次使用Haskell或Ocaml时都完全的不知所措。在Haskell里，连分号都跟别人不一样。这并不是语法的问题；Haskell和ML语言完全基于一种不同的概念、一种新的语言范式。需要用不同的方式开发应用，不同的方式组织应用，不同的方式扩展应用。所以说它入门门槛高，适用范围不广，但是学界非常喜欢，其在数学逻辑证明上的优势是其他语言望尘莫及的。而非纯函数编程语言，如Lisp，其历史悠久，也曾在相关历史时期居于某些领域(人工智能)的统治地位。 总而言之，在不同的战场上使用相适合的工具是决定编程效率的关键。而就本次实验中的编程效率来说，仅仅实现一个快排算法，C，Java和Python并无太大差别，有差别也主要是个人对于不同语言熟练性造成的，Haskell的描述函数是什么而不是命令机器怎么做的优势高下立现，程序规模是其他的一半(统计见表4-3) 3 程序规模Python&gt;=C&gt;Java&gt;&gt;Haskell 语言 快排总代码行数 实现快排函数行数 归并排序总代码行数 实现归并函数行数 C 46 24 41 41 Java 37 25 38 38 Python 46 21 45 45 Haskell 17 4 11 11 5 程序运行性能对比分析 (统一保留到小数点后一位) 快速排序 语言 常规组平均运行时间$O(nlogn)$ 小规模最坏组平均运行时间$(O(n^2))$ 大规模最坏组平均运行时间$(O(n^2))$ C 6.0 ms 1.0 ms 96.0 ms Java 14.0 ms 2.4 ms 41.8 ms Python 88.3 ms 24.5 ms 2396.9 ms Haskell 504.9 ms 284.4 ms 45812.2 ms 在常规组和小规模最坏组的实验中，符合常规的认知，效率上C最优，Java次之；对于解释型语言，Python较快，Haskell非常耗时，尤其是在n为较大值的时间复杂度(O(n^2))下 在大规模最坏组的实验中，Java比C快了一半。猜测Java在递归过程中编译器进行了优化，因为本实验未涉及几种语言的内存使用测量，故作出此猜测。 归并排序 语言 常规组平均运行时间$O(nlogn)$ 小规模组平均运行时间$O(nlogn)$ 大规模组平均运行时间$O(nlogn)$ C 13.33 ms 0.3 ms 1.6 ms Java 16.3 ms 0.8 ms 4.7 ms Python 244.5 ms 3.5 ms 41.7 ms Haskell 416.7 ms 3.2 ms 38.0 ms 归并排序是一种稳定排序，对于最好/最坏/平均都有 $ O(nlogn) $ 复杂度，在实验中确实可以得到体现；效率上以上是C最优，Java次之；对于解释性语言，常规组(规模50000) 在小规模组(规模1000)和大规模组(规模10000)的实验中，可以看到Haskell比Python有了细微的优势。但在常规组(规模50000)的实验中，python又超过了Haskell。笔者另外增加了规模80000和100000的测试： 80000规模python归并排序5次平均运行时间：374.1 ms； 80000规模haskell归并排序5次平均运行时间：477.3 ms; 100000规模python归并排序5次平均运行时间：474.1 ms; 100000规模haskell归并排序5次平均运行时间：588.2 ms; 可以看出随着数据规模增大，python又较haskell具有了优势。 6 实验心得体会 我想，大多数人的对编程语言的学习都有一个刚入门时遇到一些困难，然后逐渐轻松，云开日朗，但是之后又遇到一个巨大的瓶颈，有可能是诸如指针这样的概念，也有可能是无关语法的对算法的理解限制住了编程能力的提高。差不多所有学过编程的人都有过遇到困难的经历。我们在学了一些基本知识后，必然会遇到一些公认的概念上的关口，比如指针。很少人能轻松的掌握它们。大多数人，比如我，则需要不断的练习和参考例子来理解什么是指针、为什么它们很重要。 对于同一种思维方式的语言，如命令式语言，一旦学会几种语言后，所有的语言都开始看起来都很相似，虽然有细微差别，但入门都会相对容易。做移动互联的大作业的时候，Dart、Swift或者Kotlin的语法，它们都存在共通的地方；开发个人博客的时候，利用掌握的html我们也能把Jade、ejs的代码改得更符合我们的需求。Python的人学习Ruby可能不会遇到太多的问题，知道Java的人学习C#会感到很熟悉。不错，也有意外的地方。Ruby爱好者在学习Python时会对它的comprehension感到吃惊，Java用户会对C#里的委托摸不着头脑。还是那句话，如果只瞟一眼，它们都很相似。 但是第一次使用Haskells时我陷入了不知所措。看官方代码的一头雾水和无论如何都无法让自己的程序正确运行的焦灼不安。这并不是语法的问题；Haskell和ML语言完全基于一种不同的概念、一种新的语言范式。需要用不同的方式开发应用，不同的方式组织应用，不同的方式扩展应用。而我还是习惯性的在haskell中输入let list = quicksort [1..10]这样的命令，期望它运行。很多这样的新概念都具有不可思议的强大力量。Haskell里的Monads是跟指针一样基础且强大的概念。所以，跟学了Java后再学C#不一样，有志向学习函数式语言的人需要往回走的更远，去学习更加基础的概念后才能接下去学习。就像是完全再学习一次 说说细节上的收获，在进行大规模的实验时，我发现python、Java和Haskell都有对递归深度限制，但是C几乎是完全自由没有任何限制的。在运行速度上，解释执行的Python和Haskell自然无法与编译执行的C和Java比， Java虚拟机的启动占用一定的时间，所以在数据规模增后的快排实验中，Java要比C快了一半。","link":"/posts/53125/"},{"title":"Mac上Haskell的安装环境搭建","text":"Mac上Haskell的换源和安装 参考文章：vscode搭建haskell环境 参考文章针对的是旧版本的stack，本文针对较新版本的stack stack stack官方安装指导 Installing GHC automatically, in an isolated location.Installing packages needed for your project.Building your project.Testing your project.Benchmarking your project 正如官网所说，直接安装stack的好处是它自带Haskell的编译器GHC和Cabal(a system for building and packaging Haskell libraries and programs)等Heskell运行需要文件(个人觉得stack类似anaconda，环境管理+包管理工具)。但是国内安装不换源的话，搭建之路会很不顺利 使用brew安装stack 1brew search haskell 可以看到brew返回了两个结果，一个是Formulae下的haskell-brew，另一个是Cask类型下的haskell-for-mac，后者是个IDE，使用brew cask install haskell-for-mac下载，但是下载的过程太长，不知道到底是什么样，我们还是按照教程里的方法下载stack 1brew install haskell-stack 换源 这个时候如果按照stack官网的指示 12345stack new my-projectcd my-projectstack setupstack buildstack exec my-project-exe 很可能卡在setup步骤 第一种错误是返回Connection Failure，开全局VPN也没用那种。根据我在stackOverflow查到的信息，主要原因可能是路由器认为该地址是不良链接，拒绝了访问，无脑解决方法是直接手机开热点 第二种错误是执行stack setup之后一直卡在ghc-8.8.2: dowanload has begun其实就是原本的下载源在国外，所以下载速度起不来，所以我们要换清华的镜像源 要换的源涉及两个文件：~/.cable/config ~/.stack/config.yaml 首先换stack(stackage镜像使用帮助)和stack setup(hackage镜像使用帮助)的源，stack版本在2.1.1以上和以下不一样，这里只写2.1.1以上版本： 打开~/.stack/config.yaml，加上： 1234567891011121314151617181920setup-info: \"http://mirrors.tuna.tsinghua.edu.cn/stackage/stack-setup.yaml\"urls: latest-snapshot: http://mirrors.tuna.tsinghua.edu.cn/stackage/snapshots.jsonpackage-indices: - download-prefix: http://mirrors.tuna.tsinghua.edu.cn/hackage/ hackage-security: keyids: - 0a5c7ea47cd1b15f01f5f51a33adda7e655bc0f0b0615baa8e271f4c3351e21d - 1ea9ba32c526d1cc91ab5e5bd364ec5e9e8cb67179a471872f6e26f0ae773d42 - 280b10153a522681163658cb49f632cde3f38d768b736ddbc901d99a1a772833 - 2a96b1889dc221c17296fcc2bb34b908ca9734376f0f361660200935916ef201 - 2c6c3627bd6c982990239487f1abd02e08a02e6cf16edb105a8012d444d870c3 - 51f0161b906011b52c6613376b1ae937670da69322113a246a09f807c62f6921 - 772e9f4c7db33d251d5c6e357199c819e569d130857dc225549b40845ff0890d - aa315286e6ad281ad61182235533c41e806e5a787e0b6d1e7eef3f09d137d2e9 - fe331502606802feac15e514d9b9ea83fee8b6ffef71335479a2e68d84adc6b0 key-threshold: 3 # number of keys required # ignore expiration date, see https://github.com/commercialhaskell/stack/pull/4614 ignore-expiry: no 现在换cabal的源 在终端执行cabal update后Ctrl+C停止, 然后进行下一步。报错没关系，这一步的目的是生成~/.cabal/config配置文件 打开~/.cabal/config ，加入 12repository mirrors.tuna.tsinghua.edu.cn url: http://mirrors.tuna.tsinghua.edu.cn/hackage 为了速度，可以将官方仓库注释掉。实际有朋友反应他的配置文件中本身就没有官方仓库这一行 12-- repository hackage.haskell.org -- url: http://hackage.haskell.org/ 现在可以愉快地按照stack官方安装指导 中的步骤继续了 12345 stack new my-project cd my-projectstack setup stack buildstack exec my-project-exe 或者像python一样在终端运行.hs文件 123runhaskell filename# 或者runhs filename Hs学习笔记&lt;–To be Continued–&gt; https://www.w3cschool.cn/hsriti/","link":"/posts/32573/"},{"title":"把hexo博客部署到VPS服务器","text":"通过创建远端git仓库，将本地的hexo博客部署到远端服务器并通过Nginx服务运行 参考文章：芒果浩明 已将nginx替换为Caddy，相关文章见使用Caddy替换Nginx运行网站 操作环境及先决条件 本地macOS Catalina centOS 7的VPS 本地需要的相关环境：git、nodejs、hexo、ssh-key，相关文章见hexo博客搭建入门 服务器配置使用root身份登录服务器ssh root@IP 创建网站目录 12345678# 创建网站文件夹sudo mkdir /var/www/blog# 确认文件夹权限sudo chown git:git -R /var/www/blogsudo chown git:git -R /home/git/blog.git# 查看这两个文件夹是不是都属于git:gitll /home/git/ll /var/www/ 安装配置git 安装gitsudo yum install git 创建git用户 adduser git 假如没有提示输入密码，则passwd git 设置密码 初始化git仓库 1234# 设置文件可写chmod 740 /etc/sudoers# 编辑用户配置文件vim /etc/sudoers 找到root ALL=(ALL) ALL，换行添加git ALL=(ALL) ALL 1234567# 修改回文件权限chmod 440 /etc/sudoerssu git # 切换到git用户cd /home/git # 切换到git用户目录mkdir blog.git # 创建git仓库文件夹，以blog.git为例cd blog.git # 进入仓库目录git init --bare # 使用--bare参数初始化为裸仓库 配置Git hooks 12cd /home/git/blog.git/hooks # 切换到hooks目录下vim post-receive # 创建文件 复制下面的内容到post-receive中： 12345678#!/bin/bashGIT_REPO=/home/git/blog.gitTMP_GIT_CLONE=/tmp/blogPUBLIC_WWW=/var/www/blogrm -rf ${TMP_GIT_CLONE}git clone $GIT_REPO $TMP_GIT_CLONErm -rf ${PUBLIC_WWW}/*cp -rf ${TMP_GIT_CLONE}/* ${PUBLIC_WWW} 保存退出，执行chmod +x post-receive赋予可执行权限 配置ssh免密登录这一步可以省略，如果省略之后git部署的时候输入git的用户密码即可 本地电脑创建SSH key（已有则跳过此步骤） ssh key是让我们每次登陆的时候无需输入密码，通过本机机器码验证的方式 1234567 # 查看本地的SSH key cd ~/.sshls *.pub # 创建新的SSH keyssh-keygen -t rsa -C \"email@example.com\" # 将key加入用户列表，否则每次都会需要验证电脑登录密码ssh-add -k /Users/apple(Username)/.ssh/id_rsa 复制cat ~/.ssh/id_rsa.pub的内容 ssh连接到服务器，配置ssh秘钥登录 123cd /home/git # 切换到git用户目录mkdir .ssh # 创建.ssh目录sudo vim .ssh/authorized_keys 将复制的本地公钥粘贴到到authorized_keys文件中， 编辑登录配置sudo vim /etc/ssh/sshd_config 12345#禁用密码验证PasswordAuthentication no#启用密钥验证RSAAuthentication yesPubkeyAuthentication yes 重启ssh服务 12su root # 或者exit也可以退出到root用户service sshd restart 验证git用户能否使用ssh免密登录服务器：在本地终端，输入ssh git@IP 如果出现permission denied的的话，可能是权限问题 12chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 安装和配置nginx nginx是比较主流的网页服务器，大部分的文章都会建议使用。但是nginx的https连接配置较为复杂，如果没有特别的学习需求可以换用更为简单的Caddy。相关文章见Caddy官方文档 ，博主之后也会写相关总结 root用户身份登录到服务器 12345678# 添加nginx到yum源sudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm# 安装nginxsudo yum install -y nginx# 启动nginxsudo systemctl start nginx.service# 设置开机启动sudo systemctl enable -n nginx.service 在浏览器输入服务器IP地址，如果出现403 FORBIDDEN页面则说明nginx启动成功； 如果浏览器提示无法链接，请检查防火墙是否开启，如果开启 使用systemctl stop firewalld暂时关闭防火墙； 或者使用firewall-cmd --add-port=80/tcp --permanent开启防火墙的80端口，再使用systemctl restart firewalld.service重启防火墙。 关于防火墙的详细配置，可见本博客文章VPS和Shadowsocks配置最后一部分 nginx常用命令 1234567891011121314151617#启动service nginx start#停止nginx -s stop#查看nginx进程ps -ef | grep nginx#平滑启动nginxnginx -s reload #强制停止nginxpkill -9 nginx#检查对nginx.conf文件的修改是否正确nginx -t -c /etc/nginx/nginx.confnginx -t#查看版本nginx -v# 关闭开机启动sudo systemctl disable -n nginx.service 配置nginx 123cd /etc/nginx/conf.dsudo cp default.conf default.bak#备份sudo vim default.conf 配置文件参考 123456789101112131415161718192021222324server { listen 80; server_name localhost; root /var/www/blog; // 网站根目录 server_name annewqx.top www.annewqx.top; // 域名，没有可跳过 access_log /var/log/nginx/blog_access.log; error_log /var/log/nginx/blog_error.log; error_page 404 = /404.html; location / { root /var/www/blog; index index.html index.htm; } location / { root /var/www/blog; if (-f $request_filename) { rewrite ^/(.*)$ /$1 break; } } location /nginx_status { stub_status on; access_log off; }} nginx -s reload 重启nginx 本地操作 打开本地博客根目录下的_config.yml文件，找到最后的deploy配置，添加： 123456789# Deploymentdeploy:# github.io- type: 'git' repo: https://github.com/anne416wu/anne416wu.github.io.git # VPS- type: git repo: git@VPS的IP:blog.git branch: master 至此,hexo三联就可以把博客部署到vps了。可以在浏览器输入服务器的IP地址查看。 如果想要通过域名访问,则需要自己在域名管理那里修改解析的线路使得域名解析指向vps服务器的ip git 配置完SSH 以后，push 或者pull 的时候每次都提示Enter passphrase for key ‘/Users/Username/.ssh/id_rsa’可以这样解决 一次性：终端输入eval ssh-agent，ssh-add 永久生效：终端输入ssh-add -k /Users/m/.ssh/id_rsa 域名配置(非必须) 参考文章： Namesilo 域名购买及使用教程 Namesilo DNS 域名解析教程和常见问题解决方法汇总 博客已经搭好了，但是叫朋友看 购买域名 注册并激活NameSilo账号 搜索并购买想要注册的域名，使用优惠码go2think或okoff可减$1 付款，如果使用支付宝，则支付宝需要是绑定了邮箱的账号。我购买的时候支付宝扣了钱后半分钟又退回了，返回了失败，最后还是用的PayPal。 这里说一下题外话，最便宜的一般是.xyz域名，不到1刀，但是如果订单不满1刀的话是无法使用优惠券的。.top的域名原价$1.49/year，优惠后约等于不要钱啊。 另外长远考虑，不建议购买.me等国内无法备案的域名。 域名解析 打开域名管理页面，选择option栏下的蓝地球(DNS管理)按钮 删除原本的四个park解析记录 添加A记录，一条为example.com，一条为www.example.com DNS解析完成后生效大改需要十五分钟 可以使用域名连接你的博客了，在浏览器输入域名查看结果","link":"/posts/65182/"},{"title":"ssr to v2ray","text":"三月一日到了，成熟的小孩要学会自己换梯子的协议了 引用连接： 官方GitHub：v2ray/v2ray-core 官方网站：Project V Mac/Windows/Android客户端： 图形客户端 一键式脚本 233boy/v2ray（Github内容已经不展示） 指导手册 （需要翻墙） 指导手册备用地址 V2Ray 是一个于 Shadowsocks 之后非常好用的代理软件，但是由于 V2Ray 的配置略复杂，GUI 客户端不完善，所以 V2Ray 并没有像 Shadowsocks 在科学上网人群之中那么流行。 但目前来看ssr的服务越发不稳定，所以我们需要换用v2ray 0 先决条件 本文前导文章为 VPS和Shadowsocks配置 开了firewalld防火墙的话请自行添加对应端口 1 服务端配置 如果已经使用其他方式安装v2ray，想要换为脚本，删除方法如下： 卸载：其中 systemd 和 sysv 二选一，取决于你的系统 1234567#停用并卸载服务（systemd）：systemctl stop v2raysystemctl disable v2ray#停用并卸载服务（sysv）：service v2ray stopupdate-rc.d -f v2ray remove 删除残留文件： 12345rm -rf /etc/v2ray/* #(配置文件)rm -rf /usr/bin/v2ray/* #(程序)rm -rf /var/log/v2ray/* #(日志)rm -rf /lib/systemd/system/v2ray.service #(systemd 启动项)rm -rf /etc/init.d/v2ray #(sysv 启动项) 参考：v2ray-core/issues/187 可选用的脚本(来源：V2Ray中文网 » 好用的 V2Ray 一键脚本整理与分享 V2Ray 官方一键脚本V2Ray 官方提供 V2Ray 一键脚本，新手可以非常方便的在自己的 VPS 上一键搭建 V2Ray，详细介绍参考：V2Ray 官方教程：V2Ray 官方一键脚本搭建与配置文件生成。 233 V2Ray 一键脚本233 V2Ray 一键脚本是由 233boy 开发并维护的一个 V2Ray 脚本，是目前用的比较广泛的 V2Ray 一键脚本，自带管理面板与加速功能，详细介绍参考：233 V2Ray 一键脚本，自带管理与加速功能，v2ray.sh。 V2ray.Fun 一键脚本V2ray.Fun 是一个比较常用的 V2Ray 一键脚本，由 FunctionClub 开发并维护，这个脚本自带 Web 可视化控制面板，详细介绍参考：V2Ray 一键脚本，自带 Web 可视化控制板面板，V2ray.Fun 我选用的是233boy的脚本 ssh登陆到服务器root用户，使用一键式脚本安装 bash &lt;(curl -s -L https://git.io/v2ray.sh) 选择[1]安装； 选择默认传输协议TCP； 没有特别需要的话，回车确认默认端口； 广告拦截默认关闭(专业的人做专业的事)； 是否配置Shadowsocks看自己的需要(不过既然我们都从ss过来了，就不用了吧) 安装完成后，输入v2ray url 得到vmess URL；或者v2ray qr 得到二维码链接 备份脚本 将脚本Fork一份：备份地址 Fork后，安装在服务器上 1234git clone https://github.com/你的GitHub用户名/v2ray -b mastercd v2raychmod +x install.sh./install.sh local # 此即为运行脚本 常用命令： v2ray info 查看 V2Ray 配置信息v2ray config 修改 V2Ray 配置v2ray link 生成 V2Ray 配置文件链接v2ray infolink 生成 V2Ray 配置信息链接v2ray qr 生成 V2Ray 配置二维码链接v2ray ss 修改 Shadowsocks 配置v2ray ssinfo 查看 Shadowsocks 配置信息v2ray ssqr 生成 Shadowsocks 配置二维码链接v2ray status 查看 V2Ray 运行状态v2ray start 启动 V2Rayv2ray stop 停止 V2Rayv2ray restart 重启 V2Rayv2ray log 查看 V2Ray 运行日志v2ray update 更新 V2Rayv2ray update.sh 更新 V2Ray 管理脚本v2ray uninstall 卸载 V2Ray 2 客户端配置 打开客户端-服务器设置-左上服务器列表中‘+’-右侧url后复制粘贴刚刚得到的vmess URL即可 或者打开刚刚得到的二维码链接，直接在菜单中选择扫描屏幕上的二维码 因为v2ray的多入口多出口特性， 一个 V2Ray 进程可并发支持多个入站和出站协议，每个协议可独立工作，因此如果没有统计流量的需要，几人共用的话，不用做分割，如果有需要，请看下一部分 锐速或者加速服务我们依然可以用VPS和Shadowsocks配置 中的四合一脚本wget &quot;https://github.com/cx9208/Linux-NetSpeed/raw/master/tcp.sh&quot; &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh 重启服务即可 多用户配置 233boy的v2ray脚本中似乎没有关于这方面的快速命令，因此需要我们自己动手 使用cat /proc/sys/kernel/random/uuid新建一个用户id，记下这个ID号 打开v2ray配置文件vi /etc/v2ray/config.json 12345678910111213141516171819202122232425262728293031{ \"inbounds\": [ { //这是第一个用户的配置 \"port\": 12345, //端口号 \"protocol\": \"vmess\", \"settings\": { \"clients\": [ { \"id\": \"f8123442-a199-4ba3-b66c-3751234fbb47\", //USER ID \"level\": 1, \"alterId\": 64 } ] } }, //注意这个逗号 // 这是第二个用户的配置 { \"port\": 12346, //新的端口号 \"protocol\": \"vmess\", \"settings\": { \"clients\": [ { \"id\": \"0ff12347-7664-65d9-b10a-5b1234050c07\", //刚刚记下的USER ID \"level\": 1, \"alterId\": 64 } ] } }//注意这里没有逗号], 即完成多用户配置 使用 v2ray restart 命令重启服务 打开自动生成inbound的json文件和客户端配置链接的网站，把刚刚的新用户配置输入,点击生成链接，然后输入服务器IP，得到二维码和链接，添加到服务端即可 PAC设置从GFW LIST地址更新PAC文件 黑名单：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 白名单：https://raw.githubusercontent.com/R0uter/gfw_domain_whitelist/master/data/whitelist.pac 手动编写PAC文件以ipip.net为例 需要走代理，全匹配 1||ipip.net^ 需要直连，不走代理 1@@||example.com 详细语法规则 123456789101112131415161718192021222324=== 通配符支持 =&gt; **.example.com/ 代表 http://example.com http://233.example.com https://233.example.com https://666.example.com/233.mp4 全部走代理。同时\"*\"可省略，.example.com/ 与 *.example.com/ 效果是一样的 === 正则表达式支持以 \\ 开始和结束，\\[\\w]+:\\/\\/example.com\\ === 例外规则 =&gt; @@@@*.example.com/ 表示\"@@\"后面的网址规则(*.example.com)不走代理如：@@www.baidu.com 表示 www.baidu.com 不走代理 === 匹配地址开始和结尾规则 =&gt; ||http://example.com、example.com| 分别表示 以http://example.com开始 和 以example.com结束 的地址如：|http://233.com ，代表 http://233.com 开头的网址才会走代理，即 https://233.com http://1.233.com 都不会走代理如：233.com|，代表 233.com 结尾的网站才会走代理，即 http://233.com https://233.com http://1.233.com 都会走带了，而 http://233.com/index.html 不会走代理。 === 全匹配规则 =&gt; ||||example.com 则代表 http://example.com、https://example.com、ftp://example.com 等协议的地址全部走代理如：||233.com ，即 http://233.com、https://233.com、ftp://233.com 等地址全都走代理 === 注释规则 =&gt; !!我是注释233!我也是注释666","link":"/posts/30155/"},{"title":"使用Caddy替换Nginx运行网站","text":"Caddy的使用真的太傻瓜了! 参考文章： Caddy中文文档 3mile：如何在CentOS 7上安装和配置Caddy liuzhichao：替换 Nginx 使用 Caddy 作为博客静态服务器 本博客基于Caddy中文文档的新手入门，结合其他文章进行介绍，上接本博客博文把hexo博客部署到VPS服务器，请注意，这次你需要一个域名。 介绍为什么要用 Caddy 替换掉 Nginx ？最主要的原因是 Caddy 能让网站自动支持 HTTPS。同样是使用 Let’s Encrypt，换成 Nginx 我们就必须手工操作，并且还需要设置三个月更新证书的计划任务。而且默认还支持 http/2，很多事情都不需要我们再配置了。另外它的配置文件也比 Nginx 的要简单很多，几十行的 Nginx 配置文件 Caddy 仅需要几行就可以搞定了。 先决条件 一个搭载CentOS 7 x64的VPS服务器 一个域名example.com已被配置为指向VPS IP，具体方法参见把hexo博客部署到VPS服务器 域名部分 已经利用git把hexo博客部署到VPS的/var/www/blog文件夹 安装在Linux，Mac或BSD操作系统上，使用以下命令安装Caddy最新稳定的系统特定版本： 1curl https://getcaddy.com | bash -s personal Caddy二进制文件将被安装到该/usr/local/bin目录。使用以下命令确认： 1which caddy 输出应该是： 1/usr/local/bin/caddy 为了安全起见，切勿以root身份运行Caddy二进制文件为了让Caddy能够以非root用户的身份绑定到特权端口（例如80,443），您需要setcap按如下所示运行该命令： 1sudo setcap 'cap_net_bind_service=+ep' /usr/local/bin/caddy 测试默认情况下，Caddy使用当前目录（执行命令的目录，而不是caddy二进制文件所在目录）作为网站根目录，因此运行本地站点非常方便。 使用终端或者命令行，切换到站点目录所在： 1cd path/to/my/site # 在我们的服务器上是/var/www/blog 浏览器打开http://localhost:2015/，如果出现404页面，说明caddy运行正常，但是网站缺少默认页面。 你可以使用Ctrl+C退出，caddy将尽可能优雅中断。 配置方案1：官方指导的快速开始 如果服务器设置了防火墙，则打开80和443端口 123sudo firewall-cmd --permanent --zone=public --add-service=http sudo firewall-cmd --permanent --zone=public --add-service=httpssudo firewall-cmd --reload 请确保你的域名能解析到你的服务器，具体方法参见把hexo博客部署到VPS服务器 最后一部分 1sudo caddy -host example.com 当第一次使用一个真正的域名（不是localhost）运行Caddy时，会出现提示要求输入你的email地址。这是因为Caddy需要验证你的域名，并将验证信息安全地存储在硬盘上。 Caddy必须将40和443端口绑定到一个真正的站点，这需要root或者Administrator的权限 现在你可以打开你的网站了! &lt;全文完&gt; &lt;其实并不，Caddy可以很简单的开始，但总有高阶玩家可以把简单的事情变得更复杂，当然，也更安全&gt; 方案2：使用caddy.service(此部分有缺陷，未完成) github: systemd Service Unit for Caddy 这部分目前我遇到的问题是使用service提示用户错误。错误的原因一个是systemd version太低，虽然caddy.service要求是219即可，实际上大概是需要229以上才行；还有一个是文件夹权限的问题，涉及到用户和用户组。等有时间的时候再回头修这个吧😑 创建一个专门的系统用户：caddy 和一组同名的Caddy： 1sudo useradd -r -d /var/www -M -s /sbin/nologin caddy 注意：此处创建**的用户caddy只能用于管理Caddy服务，不能用于登录。 /var/www为Caddy Web服务器创建主目录，并/var/www/blog为您的站点创建主目录： 12sudo mkdir -p /var/www/blogsudo chown -R caddy:caddy /var/www 创建一个目录来存储SSL证书： 123sudo mkdir /etc/ssl/caddysudo chown -R caddy:root /etc/ssl/caddysudo chmod 0770 /etc/ssl/caddy 创建专用目录来存储Caddy配置文件Caddyfile： 12sudo mkdir /etc/caddysudo chown -R root:caddy /etc/caddy 创建名为的Caddy配置文件Caddyfile 以下仅是一个普通配置，详细的配置参见本文Caddyfile部分 12345678910sudo touch /etc/caddy/Caddyfilesudo chown caddy:caddy /etc/caddy/Caddyfilesudo chmod 444 /etc/caddy/Caddyfilecat &lt;&lt;EOF | sudo tee -a /etc/caddy/Caddyfileexample.com { root /var/www/blog gzip tls 邮箱账号}EOF 为了方便Caddy的操作，您可以systemd为Caddy 设置一个单元文件，然后用它systemd来管理Caddy。 123curl -s https://raw.githubusercontent.com/mholt/caddy/master/dist/init/linux-systemd/caddy.service -o /etc/systemd/system/caddy.service # 从 github 下载 systemd 配置文件chown root:root /etc/systemd/system/caddy.service # 配置权限chmod 744 /etc/systemd/system/caddy.service 启动Caddy服务并使其在系统引导时自动启动： 123sudo systemctl daemon-reloadsudo systemctl start caddy.servicesudo systemctl enable caddy.service 最后，将您的网页浏览器指向http://example.com或https://example.com。您应该看到博客运行的样子 Caddyfile **Caddyfile**用来告诉Caddy如何提供服务的文本文件。他通常和网站放在一起。 123cd path/to/siteecho example.com &gt; Caddyfilecaddy Caddy的结构如下： 12345678910111213141516171819202122232425262728293031www.mysite.com { redir https://mysite.com{uri}}mysite.com { root /var/www/blog log / /var/log/caddy/mysite.log \"{remote} {when} {method} {uri} {proto} {status} {size} {&gt;User-Agent} {latency}\" tls 邮箱账号 header / Strict-Transport-Security \"max-age=31536000\" gzip errors { 404 404.html 403 403.html } expires { match .css$ 1m match .js$ 1m match .png$ 1m match .jpg$ 1m } ipfilter / { rule block blockpage /var/www/liuzhichao.com/403.html ip 148.251.8.250 136.243.37.219 144.76.38.40 69.197.177.50 199.58.86.211 5.9.97.200 144.76.91.79 } rewrite { if {&gt;User-agent} has \"MJ12bot\" to /forbidden } status 403 /forbidden} 说明： 123www.mysite.com { redir https://mysite.com{uri}} 是将 www 跳转到非 www 的域名。 1tls mail@mysite.com tls后面改为你的邮箱地址，会自动配置 https。 1header / Strict-Transport-Security \"max-age=31536000\" 是一条 https 的优化配置，加上之后，在SSLLabs上测试评分可以拿到A+,想想之前使用 Nginx 的时候，网络上找了各种配置参考都只优化到了 A，所以 Caddy 的自动 Https 功能确实还是很方便的。 1234errors { 404 404.html 403 403.html } 是自定义错误页面配置。确保你网站的根目录有相应的文件，不然启动服务会报错。 123456expires { match .css$ 1m match .js$ 1m match .png$ 1m match .jpg$ 1m } expires 是控制页面的缓存，上面的配置是将 css,js,png,jpg 这样的静态资源缓存1个月。此配置依赖http.expires这个插件，如果你没有安装，配置后启动 caddy 会出错。 12345ipfilter / { rule block blockpage /var/www/liuzhichao.com/403.html ip 148.251.8.250 136.243.37.219 144.76.38.40 69.197.177.50 199.58.86.211 5.9.97.200 144.76.91.79 } ipfilter是根据配置过滤到一些非正常的 IP，可以查看访问log，经常会有一些爬虫频繁的访问网站，没有任何用处反而加大服务器的负载，对于这样的 IP 可以直接过滤掉。blockpage是配置这些 IP 访问网址时显示的页面，依赖http.ipfilter插件。 12345rewrite { if {&gt;User-agent} has \"MJ12bot\" to /forbidden } status 403 /forbidden 与上面的ipfilter功能类似，都是过滤掉一些非正常的访问用户，不同的是ipfilter是屏蔽 IP，这段配置则是根据User-agent block掉一些爬虫。","link":"/posts/2210/"},{"title":"编译原理与设计-Lab2-编译器认知实验","text":"GCC编译器和LLVM编译器的编译过程以及效率对比 实验目的和内容本实验主要的内容为在 Linux 平台上安装和运行工业界常用的编译器 GCC 和 LLVM，如果系统中没有安装，则需要首先安装编译器，安装完成后编写简单的测 试程序，使用编译器编译，并观察中间输出结果。 实现的内容与方法 本机环境： 系统masOS Catalina，已安装homebrew 1 编译器安装1234# 安装gcc8brew install gcc@8# 安装clangxcode-select --install 2 编写测试程序 单个程序 1234#include &lt;stdio.h&gt;int main(){ printf(\"hello\\n\");} 多个程序 cal.c 12345678#include &lt;stdio.h&gt;int add(int a,int b);int main(){ int num1, num2; scanf(\"%d %d\",&amp;num1,&amp;num2); int res = add(num1,num2); printf(\"%d\\n\", res);} add.c 1234 #include \"add.h\" int add(int num1, int num2){ return num1+num2;} 3 运行编译器进行观测GCC 查看编译器版本 12gcc -v$ gcc version 8.3.0 (Homebrew GCC 8.3.0_2) 使用gcc编译单个文件 1gcc -o hello hello.c 使用gcc编译链接多个文件 1gcc -o cal cal.c add.c 查看预处理结果 1gcc -E hello.c -o hello.i 查看语法分析树 1gcc -fdump-tree-all hello.c 生成的文件列表，使用ls -ltr 查看(按生成顺序倒序排列) 查看中间代码生成结果 1gcc -fdump-rtl-all hello.c 生成的文件列表，使用ls -ltr 查看(按生成顺序倒序排列) 查看生成的目标代码(汇编代码) 1gcc -o hello.asm -S hello.c LLVM 查看编译器的版本 1clang -v 返回结果 1234Apple clang version 11.0.0 (clang-1100.0.33.17)Target: x86_64-apple-darwin19.3.0Thread model: posixInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin 使用编译器编译单个文件 1clang -o hello hello.c 使用编译器编译链接多个文件 1clang -o cal cal.c add.c 查看编译流程和阶段 1clang -ccc-print-phases test.c -c 终端的输出： 查看词法分析结果 1clang test.c -fsyntax-only -Xclang -dump-tokens 查看词法分析结果 2: 1clang test.c -fsyntax-only -Xclang -dump-raw-tokens 生成的结果： 查看语义分析结果 12clang test.c -Xclang -ast-dump # error linkclang -fsyntax-only -Xclang -ast-dump test.c 部分结果： 查看语义分析结果 2 12clang test.c -Xclang -ast-view # clang: error: linker command failed with exit code 1 clang test.c -fsyntax-only -Xclang -ast-view # 因为缺乏gv环境 此命令未能得到成功结果 部分结果： 查看编译优化的结果: 1clang test.c -S -mllvm -print-after-all 部分结果： 查看生成的目标代码结果 Target code generation 1clang –S test.c 生成的目标代码文件开头： 运行结果分析 GCC 运行结果分析 GCC进行编译的大概步骤： 词法分析 –&gt; 语法分析 –&gt; 生成语法树 –&gt; 高级gimple –&gt; 低级gimple –&gt; cfg –&gt; ssa –&gt;RTL –&gt;目标代码(汇编代码) GENERIC、GIMPLE和RTL三者构成了gcc中间语言的全部，它们以GIMPLE为核心，由GENERIC承上，由RTL启下，在源文件和目标指令之间的鸿沟之上构建了一个三层的过渡。 预处理结果 运行gcc -E hello.c –o hello.i，将会产生 hello.i 文件，这就是 hello.c 经过预处理后的文件。原本4行的程序，经过预处理，得到了580行的预处理文件 预处理文件开头： 预处理文件结尾： 可以看到， hello.c 经过预处理后得到的 hello.i文件，除了原本的几行代码之外，还包含了很多额外的变量、函数等等，这些都是预处理器处理的结果。 语法分析树 运行gcc -fdump-tree-all hello.c后，一共生成了22个文件，其命名格式均为filename.c.&lt;num&gt;t.name 分析这22个文件内容(顺序为生成的先后顺序)： 046t.profile_estimate/318t.statistics为空白； 007t.lower/010t.eh相同； 012t.ompexp/013t.printf-return-value1/019t.fixup_cfg1相同； 020t.ssa/027t.fixup_cfg3/029t.einline/088t.fixup_cfg4/222t.veclower/223t.cplxlower0/225t.switchlower/232t.optimized相同 028t.local-fnsummary1/050t.local-fnsummary2相同 其余还有004t.gimple/006t.omplower/011t.cfg /049t.release_ssa 不与其他相同 以下重点对比源文件与004t.gimple/010(即007t.lower)/013的区别，其排序与生成顺序一致 main函数转变为高端gimple的过程 ：004t.Gimple GCC 利用 “gimplifier” 将 GENERIC 中间表示转换为 GIMPLE中间表示。 语法树到高端gimple的转化是以语法树的节点为单位进行遍历的 以函数为单位进行转化，并且将函数内部的所有变量以及编译器为方便生成运行时结构所创建的临时变量都提高到函数最开始的位置，为计算栈空间和使用寄存器提供依据 将函数执行语句集中到一起，并且其顺序与语法树种所表现的顺序一致，为配合运行时结构会增减一些语句 return语句转低端gimple的处理：007t.lower/010t.eh： GIMPLE中有一个lower的动作，用于将高层次的GIMPLE表示，解析成低层次的，这个lower动作在pass_lower_cf中完成。 高端gimple到低端gimple主要完成数据合并，代码合并和返回语句合并，有利于最后生成更规整的后端代码 在gimple_return语句的位置插入一条goto lable跳转语句 将gimple_return语句暂存起来，将gimple语句序列中的gimple_return语句删掉 待所有的语句都lower gimple转换完之后，再将gimple_return语句做gimple_return的处理，处理过程是先添加一个标号，以便于第一句的goto lable对应上，然后再把return 语句插入gimple语句序列 经过以上处理得到的低端gimple已经足以支持生成最终的目标代码，确定运行时结构了，但是gcc考虑到优化，在此基础上转化了cfg和ssa结构 低端gimple到cfg结构中间代码：012t.ompexp/013t.printf-return-value1/019t.fixup_cfg1 GCC设计cfg ( control flow graph ) 主要是用于函数内部的控制流转化，跨函数间的逻辑优化由于逻辑比较复杂，GCC目前还没有完成 cfg的主要作用是在低端gimple的基础上将语句分成几个基本块(basic block)，在基本块内，代码是顺序执行的，不存在跳转语句，如果有跳转语句，则放在块的最后，保证跳转只发生在块与块之间，即在gimple中，指令跳转的语句就是基本块的边界 013t与之后生成的hello.c.019t.fixup_cfg1/hello.c.027t.fixup_cfg3内容一致。相比007t.lower/010t.eh，语句被划分为几块，goto语句被取代。 cfg转ssa：020t.ssa 为每个变量增加一个版本号，用于数据流的优化，它的结构是跟低端gimple的结构相同的 如下cfs1与ssa的对比，变量int下多了一个版本号 中间结果及目标代码 考虑到平台的通用性，gcc生成了一套通用的RTL结构，将在RTL的基础上转化为目标代码 使用gcc -fdump-tree-all hello.c 查看生成的中间结果 生成RTL 由于GCC是支持多种平台的，在不同的平台上生成的汇编代码的格式肯定是不同的，如果为每个平台的汇编代码都写一套优化逻辑，是不太现实的，为了解决这个问题，GCC提供了一种中间形式的汇编语言RTL(Register Transfer Language)，它与具体的平台无关，这样所有的优化都可以基于RTL了，在所有的优化完成之后，再转变成针对不同硬件平台的汇编代码，每一条RTL语句称为一条insn语句 转化为RTL阶段的主要步骤 转化为初始的RTL 明确初始的RTL中的运行时结构信息，此时把虚拟寄存器更新为真实的寄存器 RTL生成目标代码，也就是汇编代码，gcc -o hello.asm -S hello.c 查看 LLVM 运行结果分析 查看编译流程和阶段clang -ccc-print-phases test.c -c 返回的结果 0：获得源代码main.c，c语言文件 1：预处理阶段，做相应处理 2：编译阶段 3：步骤通过后端进行汇编前的处理 4：汇编阶段 5：链接阶段，做相应处理通过如上步骤可以了解到整个过程以及过程中的一些信息。例如首先进行的预处理操作可以使用如下命令查看具体信息： 预处理阶段 clang -E test.c 这个过程包括宏的替换，头文件的导入等等 词法分析 在此步骤会把代码切成一个个Token，比如大小括号，等于号还有字符串等。 1234# 词法分析1clang -fsyntax-only -Xclang -dump-tokens test.c# 词法分析2clang test.c -fsyntax-only -Xclang -dump-raw-tokens 图片中依次为词法分析1，词法分析2和源文件 可以看到，-dump-raw-tokens仅仅输出我们编写的test.c的词法分析结果，而-dump-tokens输出还包括所有头文件的词法分析结果 语法分析 验证程序的语法是否正确，然后将所有的节点组成抽象语法树AST 1234# 语法分析1clang -fsyntax-only -Xclang -ast-dump test.c# 语法分析2clang test.c -fsyntax-only -Xclang -ast-view # 因为缺乏gv环境 此命令未能得到成功结果 下图依次是语法分析1得到的抽象语法树ast，语法分析2的得到的语法树生成图的源文件。test.c的源代码 这些步骤完成之后就要开始进行IR中间代码的生成了，代码生成器CodeGen会负责将语法树自顶向下遍历逐步翻译成LLVM IR，IR就是编译过程的前端的输出以及后端的输入；此步骤LLVM会去做些优化工作，在Xcode的编译设置里也可以设置优化的级别-01，-03，-0s等； 1234# 查看生成的IR中间代码clang -S -fobjc-arc -emit-llvm main.m -o main.ll# 查看LLVM编译优化的结果clang test.c -S -mllvm -print-after-all 下图依次为中间代码，LLVM编译优化的结果 生成汇编文件clang –S test.c 下图左为源文件，右为生成的汇编代码 GCC 与 LLVM 对比分析源文件均为C语言的hello world 下图左为gcc生成的汇编文件，右为llvm生成的汇编文件 优化编译 gcc提供了从O0-O3以及Os这几种不同的优化级别供大家选择 O0： 不做任何优化，这是默认的编译选项。 -O和-O1： 对程序做部分编译优化，对于大函数,优化编译占用稍微多的时间和相当大的内存。使用本项优化，编译器会尝试减小生成代码的尺寸，以及缩短执行时间，但并不执行需要占用大量编译时间的优化。 -O2： 是比O1更高级的选项，进行更多的优化。Gcc将执行几乎所有的不包含时间和空间折中的优化。当设置O2选项时，编译器并不进行循环打开（）loop unrolling以及函数内联。与O1比较而言，O2优化增加了编译时间的基础上，提高了生成代码的执行效率。 -O3： 比O2更进一步的进行优化。在包含了O2所有的优化的基础上，又打开了以下优化选项： -finline-functions：内联简单的函数到被调用函数中。由编译器启发式的决定哪些函数足够简单可以做这种内联优化。默认情况下，编译器限制内联的尺寸，3.4.6中限制为600（具体含义不详，指令条数或代码size？）可以通过-finline-limit=n改变这个长度。这种优化技术不为函数创建单独的汇编语言代码， 而是把函数代码包含在调度程序的代码中。 对于多次被调用的函数来说, 为每次函数调用复制函数代码。 虽然这样对于减少代码长度不利, 但是通过最充分的利用指令缓存代码, 而不是在每次函数调用时进行分支操作, 可以提高性能。 -fweb：构建用于保存变量的伪寄存器网络。 伪寄存器包含数据, 就像他们是寄存器一样, 但是可以使用各种其他优化技术进行优化, 比如cse和loop优化技术。这种优化会使得调试变得更加的不可能，因为变量不再存放于原本的寄存器中。 -frename-registers：在寄存器分配后，通过使用registers left over来避免预定代码中的虚假依赖。这会使调试变得非常困难，因为变量不再存放于原本的寄存器中了。 -funswitch-loops：将无变化的条件分支移出循环，取而代之的将结果副本放入循环中。 优化编译测试文件采用Lab1中的快速排序代码 GCC优化编译 规模为50000的1000000以内的不重复随机数(算法效率$O(log_n))$ 规模为50000的逆序排列(算法效率$O(n^2)$) 每组实验重复5次，最后运行时间取平均数，单位为ms 优化方式 O(logn) O(N^2) -O0 6 2830 -O1 3 505.4 -O2 4 835 -O3 3 567 gcc四种优化编译效率对比 LLVM优化编译 规模为50000的1000000以内的不重复随机数 规模为50000的逆序排列 每组实验重复5次，最后运行时间取平均数，单位为ms 优化方式 O(logn) O(N^2) -O0 6 2368 -O1 3 567 -O2 3 574 -O3 3 556 llvm四种优化编译效率对比 GCC与LLVM优化编译效果对比 可以看出，总体而言，llvm优化效率是优于gcc的 面对快排这样的少循环多递归的情况，-O2的优化效率是不如-O1和-O3的 实验心得体会 了解工业界常用的编译器 GCC 和 LLVM。以前我对编译器之前的区别并没有比较明确的认知，这此实验之后我才知道macOS系统里的gcc命令实际上调用的是clang命令； 熟悉编译器的安装和使用过程。本次实验的过程较实验1曲折了很多，过程中也遇到了很多波折，虽然很多波折是与实验本身无关的—-比如安装GCC编译器需要把下载源换为国内的tuna/USTC；wget brew等软件包管理工具，在下载软件不成功的时候会尝试下载软件的源代码，然后在本地编译； 了解编译器的优化效果。本次实验并不是我们第一次接触gcc命令，以前我们学习过了基础的gcc命令参数，怎么进行gdb调试，以及makefile的写法；通过本次实验，我终于又系统了解了一遍gcc命令的相关参数的作用，进一步了解了编译优化； 观察编译器工作过程中生成的中间文件的格式和内容。本次实验中，我进一步了解了GCC编译器编译的全过程，以及这些过程存在的原因。gcc编译的过程有词法分析 –&gt; 语法分析 –&gt; 生成语法树 –&gt; 高级gimple –&gt; 低级gimple –&gt; cfg –&gt; ssa –&gt;RTL –&gt;目标代码(汇编代码)。低端gimple已经足以支持生成最终的目标代码，确定运行结构了，但是gcc考虑到优化，还在此基础上转化了cfg和ssa结构。RTL结构是gcc为了平台的通用性而生成的一套通用的RTL结构，最终在RTL的基础上转化为汇编代码。 本次实验进一步为我们对编译器的学习和构造奠定了基础。","link":"/posts/673/"}],"tags":[{"name":"python anaconda","slug":"python-anaconda","link":"/tags/python-anaconda/"},{"name":"Terminal","slug":"Terminal","link":"/tags/Terminal/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"mac使用技巧","slug":"mac使用技巧","link":"/tags/mac%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"},{"name":"bash","slug":"bash","link":"/tags/bash/"},{"name":"VPS","slug":"VPS","link":"/tags/VPS/"},{"name":"科学上网","slug":"科学上网","link":"/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"编译原理","slug":"编译原理","link":"/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"Haskell","slug":"Haskell","link":"/tags/Haskell/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"Caddy","slug":"Caddy","link":"/tags/Caddy/"}],"categories":[{"name":"Life","slug":"Life","link":"/categories/Life/"},{"name":"Code","slug":"Code","link":"/categories/Code/"},{"name":"Fragments","slug":"Life/Fragments","link":"/categories/Life/Fragments/"},{"name":"Guide","slug":"Code/Guide","link":"/categories/Code/Guide/"},{"name":"Note","slug":"Code/Note","link":"/categories/Code/Note/"},{"name":"Other","slug":"Code/Other","link":"/categories/Code/Other/"},{"name":"report","slug":"Code/report","link":"/categories/Code/report/"}]}